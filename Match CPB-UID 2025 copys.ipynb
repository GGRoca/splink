{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c5cd3f",
   "metadata": {},
   "source": [
    "# Scipt para buscar t√≠tulos da base de dados BB para a base de dados de CPB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b64da",
   "metadata": {},
   "source": [
    "## 1) Carregamento e importa√ß√£o de bibliotecas e bases de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1083b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa bibliotecas importantes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "import os\n",
    "import unidecode\n",
    "import string\n",
    "import nltk\n",
    "import warnings\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas import ExcelWriter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega Matchs de 2024\n",
    "matchs_2024 = pd.read_excel('Bases/Matchs at√© 2024.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os datasets mais recentes da Ancine\n",
    "Base_SAD = pd.read_excel('Bases/Obras Ancine.xlsx', engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf88e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando base BB mais recente de 2025\n",
    "Base_BB_import = pd.read_excel('Bases/BB Media - 2025-08-28 - Brazil - ALL PLATFORMS.xlsx', engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66aa64-0a5d-446d-b2a4-22c0e296fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando base BB j√° percorrida\n",
    "Base_BB_2024 =  pd.read_excel('Bases/Base BB 2024 inicial.xlsx', engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Resumo das bases carregadas\n",
    "# ================================================================\n",
    "bases = {\n",
    "    'matchs_2024': matchs_2024,\n",
    "    'Base_SAD': Base_SAD,\n",
    "    'Base_BB': Base_BB_import,\n",
    "    'Base_BB_2024': Base_BB_2024\n",
    "}\n",
    "\n",
    "print(\"Resumo das bases carregadas:\\n\")\n",
    "for nome, df in bases.items():\n",
    "    print(f\"{nome:<15}: {len(df):>10,} linhas | {df.shape[1]:>3} colunas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac30c1",
   "metadata": {},
   "source": [
    "## 1.1) Limpeza de registros desnecess√°rios na base da BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4fe34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas dentro de Base_BB_1_filtrada, mantendo apenas o primeiro registro de cada UID\n",
    "Base_BB_inicial = Base_BB_import.drop_duplicates(subset='BB UID')\n",
    "\n",
    "# Contador de linhas final\n",
    "print(f\"Quantidade de linhas em Base_BB_inicial: {len(Base_BB_inicial)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68041063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar Base_BB removendo registros j√° existentes em Base_BB_2024\n",
    "Base_BB_inicial = Base_BB_inicial[~Base_BB_inicial['BB UID'].isin(Base_BB_2024['UID'])].copy()\n",
    "\n",
    "# Opcional: resetar o √≠ndice para limpeza visual\n",
    "Base_BB_inicial.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Registros restantes em Base_BB_inicial: {len(Base_BB_inicial)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c337dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Filtrando plataformas indesejadas da base Base_BB_inicial\n",
    "# ================================================================\n",
    "\n",
    "PLATAFORMAS_EXCLUIR = [\n",
    "    'Archivio Luce', 'NBA League Pass', 'iQIYI', 'Zee5', 'FIFA+', 'Qello Concerts', 'ShemarooMe',\n",
    "    'FlixOl√©', 'Rakuten Viki', 'OnDemandKorea', 'Simply South', 'Digital Concert Hall', 'IWantTFC',\n",
    "    'RT en Espa√±ol', 'KOCOWA+', 'CINE.AR PLAY', 'IFI Archive Player', 'Hoichoi', 'Selecta TV',\n",
    "    'Met Opera on Demand', 'Reel Short', 'American Indian Film Gallery', 'TVN Play', 'Teatrix',\n",
    "    'Retina Latina', 'Demand Africa', 'DAZN', 'HispanTV', 'HENRI', 'Anime Onegai', 'ALTBalaji',\n",
    "    'Digital Theatre', 'F1 TV'\n",
    "]\n",
    "\n",
    "# Contagem inicial\n",
    "total_antes = len(Base_BB_inicial)\n",
    "\n",
    "# Filtrando registros cujo campo 'Platform Name' est√° na lista\n",
    "Base_BB_inicial = Base_BB_inicial[~Base_BB_inicial['Platform Name'].isin(PLATAFORMAS_EXCLUIR)].copy()\n",
    "\n",
    "# Resetando √≠ndice\n",
    "Base_BB_inicial.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Contagem final e resumo\n",
    "total_depois = len(Base_BB_inicial)\n",
    "removidos = total_antes - total_depois\n",
    "\n",
    "print(f\"Total antes do filtro: {total_antes:,}\")\n",
    "print(f\"Total ap√≥s o filtro : {total_depois:,}\")\n",
    "print(f\"Registros removidos : {removidos:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add1e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f29b69",
   "metadata": {},
   "source": [
    "## 1.2) Resumo Estat√≠stico dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Resumo estat√≠stico e estrutural das bases Base_SAD e Base_BB_inicial\n",
    "# ================================================================\n",
    "\n",
    "def resumo_dataframe(df, nome_df):\n",
    "    \"\"\"\n",
    "    Exibe resumo de atributos e estat√≠sticas descritivas de um DataFrame\n",
    "    em formato amig√°vel e leg√≠vel no JupyterLab.\n",
    "    \"\"\"\n",
    "    display(HTML(f\"<h3 style='color:#2a5599;'>üìä Resumo da base <code>{nome_df}</code></h3>\"))\n",
    "\n",
    "    # === 1Ô∏è‚É£ Estrutura e tipos ===\n",
    "    info_df = pd.DataFrame({\n",
    "        \"Coluna\": df.columns,\n",
    "        \"Tipo de Dado\": [str(df[col].dtype) for col in df.columns],\n",
    "        \"Valores N√£o Nulos\": [df[col].notna().sum() for col in df.columns],\n",
    "        \"Valores Nulos\": [df[col].isna().sum() for col in df.columns],\n",
    "        \"% Nulos\": [df[col].isna().mean() * 100 for col in df.columns]\n",
    "    })\n",
    "\n",
    "    styled_info = (\n",
    "        info_df.style\n",
    "        .format({'% Nulos': '{:.2f}%'})\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "            {'selector': 'td', 'props': [('padding', '6px 12px')]},\n",
    "        ])\n",
    "        .set_properties(subset=['Coluna'], **{'text-align': 'left'})\n",
    "        .set_properties(subset=['Tipo de Dado'], **{'text-align': 'center'})\n",
    "        .set_properties(subset=['Valores N√£o Nulos', 'Valores Nulos', '% Nulos'], **{'text-align': 'right'})\n",
    "        .hide(axis=\"index\")\n",
    "    )\n",
    "    display(HTML(\"<h4>üìã Estrutura e Qualidade dos Dados</h4>\"))\n",
    "    display(styled_info)\n",
    "\n",
    "    # === 2Ô∏è‚É£ Estat√≠sticas descritivas ===\n",
    "    desc = df.describe(include='all').transpose().fillna(\"\")\n",
    "    styled_desc = (\n",
    "        desc.style\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "            {'selector': 'td', 'props': [('padding', '6px 12px')]},\n",
    "        ])\n",
    "        .set_properties(**{'text-align': 'right'})\n",
    "    )\n",
    "    display(HTML(\"<h4>üìà Resumo Estat√≠stico</h4>\"))\n",
    "    display(styled_desc)\n",
    "    display(HTML(\"<hr style='margin:25px 0;'>\"))\n",
    "\n",
    "# ================================================================\n",
    "# Aplica√ß√£o da fun√ß√£o √†s suas bases\n",
    "# ================================================================\n",
    "resumo_dataframe(Base_SAD, \"Base_SAD\")\n",
    "resumo_dataframe(Base_BB_inicial, \"Base_BB_inicial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10dd151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Amostra das primeiras linhas (head) das bases Base_SAD e Base_BB_inicial\n",
    "# ================================================================\n",
    "\n",
    "def exibir_head(df, nome_df, linhas=10):\n",
    "    \"\"\"\n",
    "    Exibe as primeiras linhas de um DataFrame (head) com formata√ß√£o\n",
    "    leg√≠vel no JupyterLab, no estilo de tabela do Colab.\n",
    "    \"\"\"\n",
    "    display(HTML(f\"<h3 style='color:#2a5599;'>üîé Amostra das {linhas} primeiras linhas da base <code>{nome_df}</code></h3>\"))\n",
    "\n",
    "    styled_head = (\n",
    "        df.head(linhas)\n",
    "        .style\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "            {'selector': 'td', 'props': [('padding', '6px 12px')]},\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    display(styled_head)\n",
    "    display(HTML(\"<hr style='margin:25px 0;'>\"))\n",
    "\n",
    "# ================================================================\n",
    "# Aplica√ß√£o da fun√ß√£o √†s duas bases\n",
    "# ================================================================\n",
    "exibir_head(Base_SAD, \"Base_SAD\", linhas=10)\n",
    "exibir_head(Base_BB_inicial, \"Base_BB_inicial\", linhas=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cc9d8",
   "metadata": {},
   "source": [
    "## 2) Pr√©-processamento e limpeza inicial de dados e cria√ß√£o de dataframes separados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617966dc",
   "metadata": {},
   "source": [
    "## 2.1) Trimming do dataframe da BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f15587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85141263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Selecionar apenas as colunas de interesse da base Base_BB_inicial\n",
    "# ================================================================\n",
    "\n",
    "cols_interesse = [\n",
    "    'BB UID',    'Platform Title',    'Type',    'Deeplink',    'Seasons',    'Episodes',    'Season Numbers',    'BB Cast',    'BB Countries',    'BB Directors',    'BB Duration',    'BB Languages',\n",
    "    'BB Original Title',    'BB Primary Company',    'BB Primary Country',    'BB Primary Genre',    'BB Production Companies',    'BB Title',    'BB Year',    'IMDb ID']\n",
    "\n",
    "# Mant√©m somente as colunas listadas\n",
    "Base_BB_trim = Base_BB_inicial[cols_interesse].copy()\n",
    "\n",
    "# Exibe confirma√ß√£o e amostra\n",
    "display(HTML(f\"<h4 style='color:#2a5599;'>üìã Base_BB_trim criada com {len(Base_BB_trim):,} registros e {len(Base_BB_trim.columns)} colunas.</h4>\"))\n",
    "display(Base_BB_trim.sample(5).style.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "    {'selector': 'td', 'props': [('padding', '6px 12px')]}\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_BB_trim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a33111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando o dataframe Base_BB para o formato Excel\n",
    "Base_BB_trim.to_excel('Bases/Base_BB_inicial_cortada.xlsx', index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0eafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando o dataframe Base_BB para economizar tempo de carregamento\n",
    "\n",
    "Base_BB = pd.read_excel('Bases/Base_BB_inicial_cortada.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43cca1",
   "metadata": {},
   "source": [
    "### 2.2) Preenchimento de vazios SAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e980c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2.2) Preenchimento e ajustes de colunas na Base_SAD\n",
    "# ================================================================\n",
    "\n",
    "# 1Ô∏è‚É£ Preencher vazios nos campos textuais com NaN expl√≠cito\n",
    "Base_SAD['T√≠tulo Original'] = Base_SAD['T√≠tulo Original'].fillna(np.nan)\n",
    "Base_SAD['Produtora'] = Base_SAD['Produtora'].fillna(np.nan)\n",
    "Base_SAD['Diretor'] = Base_SAD['Diretor'].fillna(np.nan)\n",
    "\n",
    "# 2Ô∏è‚É£ Renomear coluna 'Dura√ß√£o' para 'Dura√ß√£o Obra'\n",
    "if 'Dura√ß√£o' in Base_SAD.columns:\n",
    "    Base_SAD = Base_SAD.rename(columns={'Dura√ß√£o': 'Dura√ß√£o Obra'})\n",
    "\n",
    "# 3Ô∏è‚É£ Preencher vazios em 'Dura√ß√£o Obra' com zero\n",
    "if 'Dura√ß√£o Obra' in Base_SAD.columns:\n",
    "    Base_SAD['Dura√ß√£o Obra'] = Base_SAD['Dura√ß√£o Obra'].fillna(0)\n",
    "\n",
    "# 4Ô∏è‚É£ Renomear coluna 'ID_OBRA' para 'N¬∫ CPB'\n",
    "if 'ID_OBRA' in Base_SAD.columns:\n",
    "    Base_SAD = Base_SAD.rename(columns={'ID_OBRA': 'N¬∫ CPB'})\n",
    "\n",
    "# 5Ô∏è‚É£ Mensagem de confirma√ß√£o\n",
    "display(HTML(\n",
    "    \"<h4 style='color:#2a5599;'>‚úÖ Preenchimento e renomea√ß√µes conclu√≠dos com sucesso para <code>Base_SAD</code>.</h4>\"\n",
    "))\n",
    "\n",
    "display(Base_SAD.sample(10).style.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "    {'selector': 'td', 'props': [('padding', '6px 12px')]}\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8f596",
   "metadata": {},
   "source": [
    "### 2.3) Preenchimento de vazios BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2.3) Preenchimento de vazios na Base_BB\n",
    "# ================================================================\n",
    "\n",
    "# 1Ô∏è‚É£ Campos textuais ‚Äì preencher com string vazia ''\n",
    "campos_texto = [\n",
    "    'Platform Title', 'Type', 'Deeplink', 'Season Numbers',\n",
    "    'BB Cast', 'BB Countries', 'BB Directors', 'BB Languages',\n",
    "    'BB Original Title', 'BB Primary Company', 'BB Primary Country',\n",
    "    'BB Primary Genre', 'BB Production Companies', 'BB Title', 'IMDb ID'\n",
    "]\n",
    "\n",
    "for col in campos_texto:\n",
    "    if col in Base_BB.columns:\n",
    "        Base_BB[col] = Base_BB[col].fillna('').astype(str)\n",
    "\n",
    "# 2Ô∏è‚É£ Campos num√©ricos ‚Äì preencher com 0 e converter para inteiro\n",
    "campos_inteiros = ['Seasons', 'Episodes', 'BB Duration', 'BB Year']\n",
    "\n",
    "for col in campos_inteiros:\n",
    "    if col in Base_BB.columns:\n",
    "        Base_BB[col] = Base_BB[col].fillna(0).astype(int)\n",
    "\n",
    "# 3Ô∏è‚É£ Campos de identifica√ß√£o ‚Äì garantir coer√™ncia de tipo string\n",
    "if 'BB UID' in Base_BB.columns:\n",
    "    Base_BB['BB UID'] = Base_BB['BB UID'].astype(str)\n",
    "\n",
    "# 4Ô∏è‚É£ Confirma√ß√£o visual\n",
    "display(HTML(\n",
    "    \"<h4 style='color:#2a5599;'>‚úÖ Preenchimento e tipagem conclu√≠dos com sucesso para <code>Base_BB</code>.</h4>\"\n",
    "))\n",
    "display(Base_BB.sample(10).style.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "    {'selector': 'td', 'props': [('padding', '6px 12px')]}\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c22646",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_BB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075980b2",
   "metadata": {},
   "source": [
    "### 2.3) Cria√ß√£o dos dataframes e verifica√ß√£o dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ce532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d66ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a Base_SAD em filmes e s√©ries\n",
    "filmesBR_SAD = Base_SAD[Base_SAD[\"Organiza√ß√£o Temporal\"] == \"N√ÉO SERIADA\"]\n",
    "seriesBR_SAD = Base_SAD[Base_SAD[\"Organiza√ß√£o Temporal\"] != \"N√ÉO SERIADA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a Base_BB em filmes e s√©ries, considerando tamb√©m a origem BR ou Estrangeira\n",
    "filmesBR_BB = Base_BB[(Base_BB['BB Countries'].str.contains(\"BR\")) & (Base_BB['Type'].str.contains(\"Movie\"))]\n",
    "seriesBR_BB = Base_BB[(Base_BB['BB Countries'].str.contains(\"BR\")) & (Base_BB['Type'].str.contains(\"Series\"))]\n",
    "filmesEstr_BB = Base_BB[(~Base_BB['BB Countries'].str.contains(\"BR\")) & (Base_BB['Type'].str.contains(\"Movie\"))]\n",
    "seriesEstr_BB = Base_BB[(~Base_BB['BB Countries'].str.contains(\"BR\")) & (Base_BB['Type'].str.contains(\"Series\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1be418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo a quantidade de linhas nos datasets originais\n",
    "print(f\"Quantidade de linhas em Base_SAD: {len(Base_SAD)}\")\n",
    "print(f\"Quantidade de linhas em Base_BB: {len(Base_BB)}\\n\")\n",
    "\n",
    "# Imprimindo a quantidade de linhas em cada dataframe derivado\n",
    "print(f\"Quantidade de linhas em filmesBR_SAD: {len(filmesBR_SAD)}\")\n",
    "print(f\"Quantidade de linhas em seriesBR_SAD: {len(seriesBR_SAD)}\")\n",
    "print(f\"Quantidade de linhas em filmesBR_BB: {len(filmesBR_BB)}\")\n",
    "print(f\"Quantidade de linhas em seriesBR_BB: {len(seriesBR_BB)}\")\n",
    "print(f\"Quantidade de linhas em filmesEstr_BB: {len(filmesEstr_BB)}\")\n",
    "print(f\"Quantidade de linhas em seriesEstr_BB: {len(seriesEstr_BB)}\")\n",
    "\n",
    "# Compara√ß√£o entre o input e o output\n",
    "total_linhas_SAD = len(filmesBR_SAD) + len(seriesBR_SAD)\n",
    "total_linhas_BB = len(filmesBR_BB) + len(seriesBR_BB) + len(filmesEstr_BB) + len(seriesEstr_BB)\n",
    "\n",
    "print(f\"\\nCompara√ß√£o Base_SAD:\")\n",
    "print(f\"Total de linhas original: {len(Base_SAD)}\")\n",
    "print(f\"Total de linhas ap√≥s divis√£o: {total_linhas_SAD}\")\n",
    "print(f\"Diferen√ßa de linhas Base_SAD: {len(Base_SAD) - total_linhas_SAD}\")\n",
    "\n",
    "print(f\"\\nCompara√ß√£o Base_BB:\")\n",
    "print(f\"Total de linhas original: {len(Base_BB)}\")\n",
    "print(f\"Total de linhas ap√≥s divis√£o: {total_linhas_BB}\")\n",
    "print(f\"Diferen√ßa de linhas Base_BB: {len(Base_BB) - total_linhas_BB}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0034",
   "metadata": {},
   "source": [
    "### 2.4) Verifica√ß√£o de t√≠tulos hom√¥nimos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08977433",
   "metadata": {},
   "source": [
    "#### Esta verifica√ß√£o n√£o est√° criando nem separando nenhum registro ou dataframe e serve \n",
    "#### para simples confer√™ncia podendo ser desconsiderada a dependeder do contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0337fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_SAD.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda62f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3.1) Verifica√ß√£o de t√≠tulos hom√¥nimos nas bases SAD e BB\n",
    "# ================================================================\n",
    "\n",
    "def verificar_homonimos(df, nome_df, col_titulo, col_ano, col_diretor, col_id, col_titulo_alt=None):\n",
    "    \"\"\"\n",
    "    Identifica t√≠tulos hom√¥nimos dentro de uma base,\n",
    "    considerando t√≠tulo (e opcionalmente t√≠tulo alternativo), ano, diretor e identificadores √∫nicos.\n",
    "    \"\"\"\n",
    "    # Define as colunas de agrupamento dinamicamente\n",
    "    colunas_grp = [col_titulo, col_ano, col_diretor]\n",
    "    if col_titulo_alt and col_titulo_alt in df.columns and col_titulo_alt != col_titulo:\n",
    "        colunas_grp.insert(1, col_titulo_alt)  # insere o alternativo logo ap√≥s o t√≠tulo principal\n",
    "\n",
    "    # Agrupamento e contagem de identificadores distintos\n",
    "    repeticoes = (\n",
    "        df.groupby(colunas_grp)[col_id]\n",
    "        .nunique()\n",
    "        .reset_index(name='Qtd_IDs')\n",
    "    )\n",
    "\n",
    "    # Filtra apenas casos com mais de um identificador\n",
    "    repeticoes = repeticoes[repeticoes['Qtd_IDs'] > 1]\n",
    "\n",
    "    # Exibi√ß√£o formatada\n",
    "    display(HTML(f\"<h4 style='color:#2a5599;'>üé¨ Verifica√ß√£o de hom√¥nimos ‚Äî {nome_df}</h4>\"))\n",
    "    if repeticoes.empty:\n",
    "        display(HTML(\"<p style='color:green;'>‚úÖ Nenhum t√≠tulo hom√¥nimo encontrado.</p><hr>\"))\n",
    "    else:\n",
    "        display(repeticoes.style.set_table_styles([\n",
    "            {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'center')]},\n",
    "            {'selector': 'td', 'props': [('padding', '6px 12px')]}\n",
    "        ]))\n",
    "        print(f\"\\nQuantidade de t√≠tulos hom√¥nimos em {nome_df}: {len(repeticoes)}\\n\")\n",
    "        display(HTML(\"<hr style='margin:25px 0;'>\"))\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Aplica√ß√£o √†s bases\n",
    "# ================================================================\n",
    "\n",
    "# --- Filmes e s√©ries brasileiras (SAD)\n",
    "verificar_homonimos(\n",
    "    filmesBR_SAD,\n",
    "    \"Filmes Brasileiros (SAD)\",\n",
    "    \"T√≠tulo Original\",\n",
    "    \"Ano de Produ√ß√£o\",\n",
    "    \"Diretor\",\n",
    "    \"N¬∫ CPB\"\n",
    ")\n",
    "\n",
    "verificar_homonimos(\n",
    "    seriesBR_SAD,\n",
    "    \"S√©ries Brasileiras (SAD)\",\n",
    "    \"T√≠tulo Original\",\n",
    "    \"Ano de Produ√ß√£o\",\n",
    "    \"Diretor\",\n",
    "    \"N¬∫ CPB\"\n",
    ")\n",
    "\n",
    "# --- Filmes e s√©ries brasileiras (BB)\n",
    "verificar_homonimos(\n",
    "    filmesBR_BB,\n",
    "    \"Filmes Brasileiros (BB)\",\n",
    "    \"Platform Title\",\n",
    "    \"BB Year\",\n",
    "    \"BB Directors\",\n",
    "    \"BB UID\",\n",
    "    col_titulo_alt=\"BB Original Title\"\n",
    ")\n",
    "\n",
    "verificar_homonimos(\n",
    "    seriesBR_BB,\n",
    "    \"S√©ries Brasileiras (BB)\",\n",
    "    \"Platform Title\",\n",
    "    \"BB Year\",\n",
    "    \"BB Directors\",\n",
    "    \"BB UID\",\n",
    "    col_titulo_alt=\"BB Original Title\"\n",
    ")\n",
    "\n",
    "# --- Filmes e s√©ries estrangeiras (BB)\n",
    "verificar_homonimos(\n",
    "    filmesEstr_BB,\n",
    "    \"Filmes Estrangeiros (BB)\",\n",
    "    \"Platform Title\",\n",
    "    \"BB Year\",\n",
    "    \"BB Directors\",\n",
    "    \"BB UID\",\n",
    "    col_titulo_alt=\"BB Original Title\"\n",
    ")\n",
    "\n",
    "verificar_homonimos(\n",
    "    seriesEstr_BB,\n",
    "    \"S√©ries Estrangeiras (BB)\",\n",
    "    \"Platform Title\",\n",
    "    \"BB Year\",\n",
    "    \"BB Directors\",\n",
    "    \"BB UID\",\n",
    "    col_titulo_alt=\"BB Original Title\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d1ccdbc-de50-4e7e-8acf-3245b69e11d3",
   "metadata": {},
   "source": [
    "# ================================================================\n",
    "# 3.2) Gera√ß√£o e exporta√ß√£o das coincid√™ncias SAD para Excel\n",
    "# ================================================================\n",
    "\n",
    "# --- 1Ô∏è‚É£ Recriar DataFrames de repeti√ß√µes (sem exibir)\n",
    "repeticoes_filmesBR_SAD = (\n",
    "    filmesBR_SAD\n",
    "    .groupby(['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor'])['N¬∫ CPB']\n",
    "    .nunique()\n",
    "    .reset_index(name='Qtd_IDs')\n",
    ")\n",
    "repeticoes_filmesBR_SAD = repeticoes_filmesBR_SAD[repeticoes_filmesBR_SAD['Qtd_IDs'] > 1]\n",
    "\n",
    "repeticoes_seriesBR_SAD = (\n",
    "    seriesBR_SAD\n",
    "    .groupby(['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor'])['N¬∫ CPB']\n",
    "    .nunique()\n",
    "    .reset_index(name='Qtd_IDs')\n",
    ")\n",
    "repeticoes_seriesBR_SAD = repeticoes_seriesBR_SAD[repeticoes_seriesBR_SAD['Qtd_IDs'] > 1]\n",
    "\n",
    "# --- 2Ô∏è‚É£ Cruzar com as bases originais para trazer os registros completos\n",
    "coinc_filmes_SAD = filmesBR_SAD.merge(\n",
    "    repeticoes_filmesBR_SAD[['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor']],\n",
    "    on=['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor'],\n",
    "    how='inner'\n",
    ")\n",
    "coinc_series_SAD = seriesBR_SAD.merge(\n",
    "    repeticoes_seriesBR_SAD[['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor']],\n",
    "    on=['T√≠tulo Original', 'Ano de Produ√ß√£o', 'Diretor'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# --- 3Ô∏è‚É£ Selecionar apenas colunas de interesse\n",
    "colunas_exportar = [\n",
    "    'N¬∫ CPB', 'T√≠tulo Original', 'T√≠tulo Alternativo', 'Classifica√ß√£o',\n",
    "    'G√™nero', 'Organiza√ß√£o Temporal', 'Dura√ß√£o',\n",
    "    'N¬∫ de Epis√≥dios', 'Ano de Produ√ß√£o', 'Produtora', 'Diretor'\n",
    "]\n",
    "\n",
    "coinc_filmes_SAD = coinc_filmes_SAD[[c for c in colunas_exportar if c in coinc_filmes_SAD.columns]]\n",
    "coinc_series_SAD = coinc_series_SAD[[c for c in colunas_exportar if c in coinc_series_SAD.columns]]\n",
    "\n",
    "# --- 4Ô∏è‚É£ Exportar para Excel\n",
    "caminho_saida = f\"Coincidencias_SAD_{pd.Timestamp.now():%Y-%m-%d_%Hh%M}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(caminho_saida, engine=\"openpyxl\") as writer:\n",
    "    coinc_filmes_SAD.to_excel(writer, sheet_name=\"Filmes_SAD\", index=False)\n",
    "    coinc_series_SAD.to_excel(writer, sheet_name=\"Series_SAD\", index=False)\n",
    "\n",
    "# --- 5Ô∏è‚É£ Mensagem de confirma√ß√£o\n",
    "display(HTML(f\"\"\"\n",
    "<h4 style='color:#2a5599;'>‚úÖ Arquivo gerado com sucesso:</h4>\n",
    "<p><code>{os.path.abspath(caminho_saida)}</code></p>\n",
    "<ul>\n",
    "<li>üìÑ Aba 1: Filmes_SAD ‚Üí {len(coinc_filmes_SAD):,} registros</li>\n",
    "<li>üìÑ Aba 2: Series_SAD ‚Üí {len(coinc_series_SAD):,} registros</li>\n",
    "</ul>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb753976",
   "metadata": {},
   "source": [
    "## 3) Processamento para uniformiza√ß√£o de campos de texto e num√©ricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f31d19",
   "metadata": {},
   "source": [
    "### 3.1) Defini√ß√£o das fun√ß√µes de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d87635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria√ß√£o de c√≥pias limpas dos DataFrames\n",
    "filmesBR_SAD_limpo = filmesBR_SAD.copy()\n",
    "seriesBR_SAD_limpo = seriesBR_SAD.copy()\n",
    "\n",
    "filmesBR_BB_limpo = filmesBR_BB.copy()\n",
    "seriesBR_BB_limpo = seriesBR_BB.copy()\n",
    "\n",
    "filmesEstr_BB_limpo = filmesEstr_BB.copy()\n",
    "seriesEstr_BB_limpo = seriesEstr_BB.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para transformar numerais romanos para ar√°bicos\n",
    "def roman_to_arabic(roman):\n",
    "    roman_numerals = {\n",
    "        'i': 1,\n",
    "        'ii': 2,\n",
    "        'iii': 3,\n",
    "        'iv': 4,\n",
    "        'v': 5,\n",
    "        'vi': 6,\n",
    "        'vii': 7,\n",
    "        'viii': 8,\n",
    "        'ix': 9,\n",
    "        'x': 10\n",
    "    }\n",
    "    \n",
    "    return roman_numerals.get(roman.lower(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082fd87-7e51-43ce-8b3f-6c30565e6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _colapsar_sigla_pontilhada(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    # casa sequ√™ncias de letra+ponto repetidas (2+ letras), opcional letra final e ponto\n",
    "    # exemplos cobertos: \"L.A.P.A.\", \"U.S.A\", \"F.B.I.\", \"L. A. P. A.\"\n",
    "    return re.sub(r'(?i)(?:\\b[a-z]\\s*\\.){2,}[a-z]?\\s*\\.?', \n",
    "                  lambda m: re.sub(r'[\\s\\.]', '', m.group(0)), \n",
    "                  s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd11bd-e42f-46c1-b888-a2a372790e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonempty_str(series_or_str):\n",
    "    s = pd.Series(series_or_str) if not isinstance(series_or_str, pd.Series) else series_or_str\n",
    "    s = s.astype(str).str.strip()\n",
    "    return s.notna() & s.ne('') & s.str.lower().ne('nan') & s.str.lower().ne('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800fa7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para realizar as transforma√ß√µes de strings\n",
    "def process_string3(s):\n",
    "    if not isinstance(s, str):  # Se n√£o for uma string, retorne como est√°\n",
    "        return s\n",
    "    \n",
    "    # Corrigir espa√ßamento antes e depois de v√≠rgulas\n",
    "    s = re.sub(r'\\s*,\\s*', ', ', s)\n",
    "    s = s.lower().strip()  # Converter texto para min√∫sculo e remover espa√ßos no come√ßo/fim\n",
    "    \n",
    "    # Remover caracteres n√£o latinos (Chineses por exemplo)\n",
    "    s = re.sub(r'[^\\u0000-\\u024F\\u1E00-\\u1EFF]+', '', s)\n",
    "    \n",
    "    # Remover refer√™ncias de temporadas\n",
    "    patterns = [\n",
    "    r'(\\s*-?\\s*season\\s*\\d+)$',\n",
    "    r'(\\s*-?\\s*\\d+\\s*[¬∫¬™¬∞]?\\s*temporada)$',\n",
    "    r'(\\s*-?\\s*\\d+[a¬™]?\\s*temp)$',\n",
    "    r'(\\s*-?\\s*\\d+rd\\s*season)$',\n",
    "    r'(\\s*-?\\s*\\d+th\\s*season)$',\n",
    "    r'(\\s*-?\\s*(primeira|segunda|terceira|quarta|quinta|sexta|s√©tima|oitava|nona|d√©cima)\\s*temporada)$',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        s = re.sub(pattern, '', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    \n",
    "    # Converter numerais romanos para ar√°bicos\n",
    "    words = s.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in ['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x']:\n",
    "            words[i] = str(roman_to_arabic(word))\n",
    "    s = ' '.join(words)\n",
    "    \n",
    "    # Substituir ¬∞ por o antes de remover acentos\n",
    "    s = s.replace('¬∞', 'o')\n",
    "    s = s.replace('¬∞', 'o')\n",
    "    s = s.replace('¬™', 'a')\n",
    "\n",
    "    # COLAPSAR SIGLAS PONTILHADAS ANTES DE REMOVER PONTUA√á√ÉO\n",
    "    s = _colapsar_sigla_pontilhada(s)\n",
    "    \n",
    "    # Transformar caracteres de pontua√ß√£o em espa√ßos\n",
    "    for char in string.punctuation:\n",
    "        s = s.replace(char, ' ')\n",
    "    \n",
    "    # Converter caracteres acentuados para sua vers√£o sem acentua√ß√£o\n",
    "    s = unidecode.unidecode(s)\n",
    "    \n",
    "    # Remover palavras comuns\n",
    "    common_words = ['o', 'a', 'os', 'as', 'um', 'uma', 'do', 'da', 'dos', 'das', 'e', 'the']\n",
    "    s = ' '.join([word for word in s.split() if word not in common_words])\n",
    "    \n",
    "    # Remover espa√ßos excessivos\n",
    "    s = re.sub(' +', ' ', s)   \n",
    "    \n",
    "\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_palavras_espec√≠ficas2(s):\n",
    "    \"\"\"\n",
    "    Remove m√∫ltiplas siglas empresariais no final do nome da produtora.\n",
    "    Exemplos:\n",
    "      - 'LTDA - ME'\n",
    "      - 'EIRELI - ME'\n",
    "      - 'LTDA. - ME - BAIXADO'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "\n",
    "    s = \" \" + s.strip() + \" \"\n",
    "\n",
    "    # Padroniza pontua√ß√£o comum\n",
    "    s = re.sub(r'[\\.\\-‚Äì]+', ' ', s)\n",
    "\n",
    "    # Lista ampliada de siglas empresariais comuns\n",
    "    palavras_especificas = [\n",
    "        's', 'me', 'ltd', 'ltda', 'inc', 'sa', 'eireli', 'mei', 'corp', 'epp', 'ei'\n",
    "    ]\n",
    "\n",
    "    # Remove todas as ocorr√™ncias dessas siglas no final (pode haver mais de uma)\n",
    "    while True:\n",
    "        s_antigo = s\n",
    "        for palavra in palavras_especificas:\n",
    "            s = re.sub(rf'\\s{palavra}\\s*$', ' ', s, flags=re.IGNORECASE)\n",
    "        if s == s_antigo:\n",
    "            break\n",
    "\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remover CPFs ou blocos num√©ricos no in√≠cio\n",
    "\n",
    "def remove_cpf_inicio(s):\n",
    "    \"\"\"\n",
    "    Remove CPF ou blocos num√©ricos no in√≠cio da string.\n",
    "    Casos tratados:\n",
    "      - '123456789 Nome'\n",
    "      - '123.456.789 Nome'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "\n",
    "    s = s.strip()\n",
    "\n",
    "    # Caso 1: primeiros 9 caracteres s√£o todos d√≠gitos + espa√ßo\n",
    "    if re.match(r'^\\d{9}\\s', s):\n",
    "        return s[10:].strip()\n",
    "\n",
    "    # Caso 2: padr√£o CPF formatado com pontos ‚Äî 11 d√≠gitos no formato XXX.XXX.XXX\n",
    "    s = re.sub(r'^\\d{3}\\.\\d{3}\\.\\d{3}\\s+', '', s)\n",
    "\n",
    "    return s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75b02d-ba81-4606-a6e6-316ed4a1d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remover CPFs ou blocos num√©ricos no final\n",
    "\n",
    "def remove_cpf_fim(s):\n",
    "    \"\"\"\n",
    "    Remove CPF no FINAL do texto da produtora.\n",
    "    Casos tratados:\n",
    "      - '... 123456789'\n",
    "      - '... 123.456.789'\n",
    "      - '... - 123456789' / '... - 123.456.789'\n",
    "      - '... (123456789)' / '... (123.456.789)'\n",
    "    N√£o altera outros n√∫meros, pois exige exatamente 9 d√≠gitos (com ou sem pontos).\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "\n",
    "    s = s.strip()\n",
    "\n",
    "    # remove bloco final: [opcional ' - ' ou par√™nteses] + (XXX.XXX.XXX | XXXXXXXXX) + final de string\n",
    "    s = re.sub(r'[\\s\\-\\‚Äì\\(\\)]*(?:\\d{3}\\.\\d{3}\\.\\d{3}|\\d{9})\\s*$', '', s, flags=re.IGNORECASE)\n",
    "\n",
    "    return s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba07ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para transformar o campo de texto do ano de produ√ß√£o em dois campos numericos: Ano inicial e Ano final\n",
    "def extract_ano_inicial(year_value):\n",
    "    # Converter o valor para string\n",
    "    year_string = str(year_value)\n",
    "    \n",
    "    # Se 'A' estiver presente, extraia o ano antes do 'A'\n",
    "    if 'A' in year_string:\n",
    "        return int(year_string.split(' A ')[0])\n",
    "    # Se for apenas um ano, retorne esse ano\n",
    "    elif year_string.isdigit():\n",
    "        return int(year_string)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_ano_final(year_value):\n",
    "    # Converter o valor para string\n",
    "    year_string = str(year_value)\n",
    "    \n",
    "    # Se 'A' estiver presente, extraia o ano ap√≥s o 'A'\n",
    "    if 'A' in year_string:\n",
    "        return int(year_string.split(' A ')[1])\n",
    "    # Se for apenas um ano, retorne esse mesmo ano\n",
    "    elif year_string.isdigit():\n",
    "        return int(year_string)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b929bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_baixada(s):\n",
    "    \"\"\"\n",
    "    Remove ocorr√™ncias de 'baixado' ou 'baixada' (com h√≠fen, espa√ßo ou par√™nteses).\n",
    "    Exemplos tratados:\n",
    "      - '(BAIXADA)'\n",
    "      - '- BAIXADO'\n",
    "      - '- BAIXADA'\n",
    "      - '(BAIXADO)'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "\n",
    "    s = s.strip()\n",
    "\n",
    "    # Remove qualquer ocorr√™ncia no final, com ou sem par√™nteses ou h√≠fen\n",
    "    pattern = r'[\\s\\-\\(]*(baixad[ao])[\\s\\)]*$'\n",
    "    return re.sub(pattern, '', s, flags=re.IGNORECASE).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ad777-cfd1-4518-b3db-4d6ef0585781",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_pt = {'da','de','do','das','dos'}\n",
    "\n",
    "def _normalize_name_basic(s: str) -> str:\n",
    "    s = '' if pd.isna(s) else str(s).strip().lower()\n",
    "    s = unidecode.unidecode(s)\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def surnames_from_raw(raw: str) -> set:\n",
    "    \"\"\"\n",
    "    Divide por V√çRGULA, normaliza cada nome e extrai o sobrenome 'de verdade':\n",
    "    - √∫ltimo token; se pen√∫ltimo ‚àà {da,de,do,das,dos}, pega 'pen√∫ltimo + √∫ltimo' (ex.: 'da silva').\n",
    "    \"\"\"\n",
    "    if pd.isna(raw) or not str(raw).strip():\n",
    "        return set()\n",
    "    out = set()\n",
    "    for p in str(raw).split(','):\n",
    "        n = _normalize_name_basic(p)\n",
    "        if not n:\n",
    "            continue\n",
    "        toks = n.split()\n",
    "        if not toks:\n",
    "            continue\n",
    "        # '... da silva' -> 'da silva'\n",
    "        if len(toks) >= 2 and toks[-2] in particles_pt:\n",
    "            out.add(toks[-2] + ' ' + toks[-1])\n",
    "        else:\n",
    "            out.add(toks[-1])\n",
    "    return out\n",
    "\n",
    "def tokens_empresas(s: str) -> set:\n",
    "    \"\"\"\n",
    "    Usa campos *_processado (j√° sem ltda, me, etc.) e quebra em tokens distintivos.\n",
    "    \"\"\"\n",
    "    if pd.isna(s) or not str(s).strip():\n",
    "        return set()\n",
    "    t = str(s).strip().split()\n",
    "    return set([w for w in t if len(w) > 2])  # ignora tokens 1‚Äì2 letras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eeb0a1",
   "metadata": {},
   "source": [
    "### 3.2) Aplica√ß√£o das Fun√ß√µes para uniformiza√ß√£o de campos textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b611e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 3.2 Aplica√ß√£o das Fun√ß√µes para uniformiza√ß√£o de campos textuais\n",
    "# ===================================================================================\n",
    "\n",
    "# ================================================\n",
    "# Bases SAD\n",
    "# ================================================\n",
    "for df in [filmesBR_SAD_limpo, seriesBR_SAD_limpo]:\n",
    "    \n",
    "    # --- Normaliza√ß√£o base (acentos, pontua√ß√£o, caixa etc.)\n",
    "    df['T√≠tulo Original_processado'] = df['T√≠tulo Original'].apply(process_string3)\n",
    "    df['Diretor_processado']         = df['Diretor'].apply(process_string3)\n",
    "    df['Produtora_processada']       = df['Produtora'].apply(process_string3)\n",
    "    \n",
    "    # --- Remo√ß√£o de CPF no in√≠cio e no final das strings\n",
    "    df['Produtora_processada'] = df['Produtora_processada'].apply(remove_cpf_inicio)\n",
    "    df['Produtora_processada'] = df['Produtora_processada'].apply(remove_cpf_fim)\n",
    "    \n",
    "    # --- Remo√ß√£o de indica√ß√µes de \"baixado(a)\" em diferentes formatos\n",
    "    df['Produtora_processada'] = df['Produtora_processada'].apply(remove_last_baixada)\n",
    "    df['Diretor_processado']   = df['Diretor_processado'].apply(remove_last_baixada)\n",
    "    \n",
    "    # --- Remo√ß√£o de siglas empresariais (LTDA, ME, EIRELI etc.)\n",
    "    df['Produtora_processada'] = df['Produtora_processada'].apply(remove_palavras_espec√≠ficas2)\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# Bases BB_BR\n",
    "# ================================================\n",
    "for df in [filmesBR_BB_limpo, seriesBR_BB_limpo]:\n",
    "    \n",
    "    # --- Normaliza√ß√£o base\n",
    "    df['Platform Title_processado']          = df['Platform Title'].apply(process_string3)\n",
    "    df['BB Original Title_processado']       = df['BB Original Title'].apply(process_string3)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company'].apply(process_string3)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies'].apply(process_string3)\n",
    "    df['BB Directors_processado']            = df['BB Directors'].apply(process_string3)\n",
    "    df['BB Title_processado']                = df['BB Title'].apply(process_string3)\n",
    "    \n",
    "    # --- Remo√ß√£o de CPF no in√≠cio e no final das strings (para produtoras)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_cpf_inicio)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_cpf_fim)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_cpf_inicio)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_cpf_fim)\n",
    "    \n",
    "    # --- Remo√ß√£o de \"baixado(a)\" e variantes\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_last_baixada)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_last_baixada)\n",
    "    \n",
    "    # --- Remo√ß√£o de siglas empresariais (LTDA, ME, EIRELI etc.)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_palavras_espec√≠ficas2)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_palavras_espec√≠ficas2)\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# Bases BB_estrangeiras\n",
    "# ================================================\n",
    "\n",
    "for df in [filmesEstr_BB_limpo, seriesEstr_BB_limpo]:\n",
    "    # 1) Normaliza√ß√£o base\n",
    "    df['Platform Title_processado']          = df['Platform Title'].apply(process_string3)\n",
    "    df['BB Original Title_processado']       = df['BB Original Title'].apply(process_string3)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company'].apply(process_string3)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies'].apply(process_string3)\n",
    "    df['BB Directors_processado']            = df['BB Directors'].apply(process_string3)\n",
    "    df['BB Title_processado']                = df['BB Title'].apply(process_string3)\n",
    "\n",
    "    # 2) Remo√ß√£o de CPF no in√≠cio e no fim (produtoras)\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_cpf_inicio).apply(remove_cpf_fim)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_cpf_inicio).apply(remove_cpf_fim)\n",
    "\n",
    "    # 3) Remo√ß√£o de ‚Äúbaixado/baixada‚Äù\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_last_baixada)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_last_baixada)\n",
    "\n",
    "    # 4) Remo√ß√£o de siglas empresariais\n",
    "    df['BB Production Companies_processado'] = df['BB Production Companies_processado'].apply(remove_palavras_espec√≠ficas2)\n",
    "    df['BB Primary Company_processado']      = df['BB Primary Company_processado'].apply(remove_palavras_espec√≠ficas2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b98de-fd77-40df-bcca-88a40c749bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 3.3 Amostras das bases processadas\n",
    "# ===================================================================================\n",
    "\n",
    "def mostrar_amostra(df, titulo):\n",
    "    display(HTML(f\"<h4 style='color:#006699;'>{titulo}</h4>\"))\n",
    "    display(df.sample(5).style.set_table_attributes(\"style='display:inline'\").set_caption(titulo))\n",
    "    display(HTML(\"<hr style='margin:25px 0;'>\"))\n",
    "\n",
    "# Exibir amostras\n",
    "mostrar_amostra(filmesBR_SAD_limpo, \"üé¨ Filmes Brasileiros (SAD)\")\n",
    "mostrar_amostra(seriesBR_SAD_limpo, \"üì∫ S√©ries Brasileiras (SAD)\")\n",
    "mostrar_amostra(filmesBR_BB_limpo, \"üéûÔ∏è Filmes Brasileiros (BB)\")\n",
    "mostrar_amostra(seriesBR_BB_limpo, \"üì° S√©ries Brasileiras (BB)\")\n",
    "mostrar_amostra(filmesEstr_BB_limpo, \"üåç Filmes Estrangeiros (BB)\")\n",
    "mostrar_amostra(seriesEstr_BB_limpo, \"üåç S√©ries Estrangeiras (BB)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc3758",
   "metadata": {},
   "source": [
    "### 3.3) Cria√ß√£o e tratamento dos campos de Ano de Produ√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desativar warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Aplicando as fun√ß√µes e criando as novas colunas nos DataFrames SAD\n",
    "for df in [filmesBR_SAD_limpo, seriesBR_SAD_limpo]:\n",
    "    df['Ano Inicial'] = df['Ano de Produ√ß√£o'].apply(extract_ano_inicial)\n",
    "    df['Ano Final'] = df['Ano de Produ√ß√£o'].apply(extract_ano_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [filmesBR_BB_limpo, seriesBR_BB_limpo]:\n",
    "    df['BB Year'] = df['BB Year'].fillna(0).astype(int)\n",
    "    \n",
    "# Reativar warnings\n",
    "warnings.simplefilter(action='default', category=pd.errors.SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be25e4-492f-4e5a-9c0d-519161463b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Convers√£o de tipos num√©ricos (SAD) com valida√ß√£o\n",
    "cols_int_sad = ['Ano Inicial',\t'Ano Final', 'N¬∫ de Epis√≥dios'] \n",
    "\n",
    "def to_nullable_int(series, nome):\n",
    "    s = pd.to_numeric(series, errors='coerce')\n",
    "    frac = (s % 1).fillna(0)\n",
    "    # valida: s√≥ aceita inteiros exatos (fra√ß√£o = 0)\n",
    "    if (frac != 0).any():\n",
    "        # mostra exemplos problem√°ticos e aborta\n",
    "        bad = series[(frac != 0)]\n",
    "        raise ValueError(f\"Coluna '{nome}' cont√©m valores n√£o-inteiros, ex.: {bad.head(10).tolist()}\")\n",
    "    return s.astype('Int64')\n",
    "\n",
    "for c in cols_int_sad:\n",
    "    if c in filmesBR_SAD_limpo.columns:\n",
    "        filmesBR_SAD_limpo[c] = to_nullable_int(filmesBR_SAD_limpo[c], c)\n",
    "    if c in seriesBR_SAD_limpo.columns:\n",
    "        seriesBR_SAD_limpo[c]  = to_nullable_int(seriesBR_SAD_limpo[c], c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892b1cc-5875-41d6-9fe0-775fdc2f1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3.3 ‚Äî Materializa√ß√£o de features para Matching (pr√©-c√°lculo)\n",
    "# ================================================================\n",
    "\n",
    "def _prod_tokens_union(row):\n",
    "    s1 = row['BB Primary Company_processado']\n",
    "    s2 = row['BB Production Companies_processado']\n",
    "    toks = set()\n",
    "    if isinstance(s1, str) and s1.strip():\n",
    "        toks |= tokens_empresas(s1)\n",
    "    if isinstance(s2, str) and s2.strip() and s2 != s1:\n",
    "        toks |= tokens_empresas(s2)\n",
    "    return toks\n",
    "\n",
    "# SAD (filmes e s√©ries)\n",
    "for df in [filmesBR_SAD_limpo, seriesBR_SAD_limpo]:\n",
    "    df['dir_set_sad']      = df['Diretor'].apply(surnames_from_raw)             # usa campo RAW (separado por v√≠rgula)\n",
    "    df['prod_tokens_sad']  = df['Produtora_processada'].apply(tokens_empresas)  # j√° normalizada\n",
    "\n",
    "# BB (filmes/s√©ries nacionais e estrangeiros)\n",
    "for df in [filmesBR_BB_limpo, seriesBR_BB_limpo, filmesEstr_BB_limpo, seriesEstr_BB_limpo]:\n",
    "    df['dir_set_bb']       = df['BB Directors'].apply(surnames_from_raw)        # usa campo RAW (separado por v√≠rgula)\n",
    "    df['prod_tokens_bb']   = df.apply(_prod_tokens_union, axis=1)               # uni√£o: Primary + Companies (se diferentes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdbe39",
   "metadata": {},
   "source": [
    "### 3.5) Verifica√ß√£o dos resultados ap√≥s transforma√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filmesBR_SAD_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(filmesBR_SAD_limpo.describe())  # Resumo estat√≠stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seriesBR_SAD_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(seriesBR_SAD_limpo.describe())  # Resumo estat√≠stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbef9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filmesBR_BB_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(filmesBR_BB_limpo.describe())  # Resumo estat√≠stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44666f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seriesBR_BB_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(seriesBR_BB_limpo.describe())  # Resumo estat√≠stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf91715-a1ed-48c0-aded-09a3e4d25478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filmesEstr_BB_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(filmesEstr_BB_limpo.describe())  # Resumo estat√≠stico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0129d7-baca-49af-83d9-02525f9b05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seriesEstr_BB_limpo.info())  # Resumo dos atributos\n",
    "print(\"\\nResumo Estat√≠stico:\")\n",
    "print(seriesEstr_BB_limpo.describe())  # Resumo estat√≠stico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fd2da",
   "metadata": {},
   "source": [
    "### 3.6) Salva bases Limpas para importa√ß√£o futura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do arquivo de sa√≠da\n",
    "arquivo = 'Pre-processamento bases limpas.xlsx'\n",
    "\n",
    "# Usando ExcelWriter para salvar os DataFrames em abas diferentes\n",
    "with pd.ExcelWriter(arquivo, engine='openpyxl') as writer:\n",
    "    # Escrevendo cada DataFrame em uma aba separada\n",
    "    filmesBR_SAD_limpo.to_excel(writer, sheet_name='Filmes SAD', index=False)\n",
    "    seriesBR_SAD_limpo.to_excel(writer, sheet_name='S√©ries SAD', index=False)\n",
    "    filmesBR_BB_limpo.to_excel(writer, sheet_name='Filmes BR BB', index=False)\n",
    "    seriesBR_BB_limpo.to_excel(writer, sheet_name='S√©ries BR BB', index=False)\n",
    "    filmesEstr_BB_limpo.to_excel(writer, sheet_name='Filmes Estr BB', index=False)\n",
    "    seriesEstr_BB_limpo.to_excel(writer, sheet_name='S√©ries Estr BB', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47166bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera bases limpas\n",
    "arquivo = 'Pre-processamento bases limpas.xlsx'\n",
    "filmesBR_SAD_limpo = pd.read_excel(arquivo, sheet_name='Filmes SAD')\n",
    "seriesBR_SAD_limpo = pd.read_excel(arquivo, sheet_name='S√©ries SAD')\n",
    "filmesBR_BB_limpo = pd.read_excel(arquivo, sheet_name='Filmes BR BB')\n",
    "seriesBR_BB_limpo = pd.read_excel(arquivo, sheet_name='S√©ries BR BB')\n",
    "filmesEstr_BB_limpo = pd.read_excel(arquivo, sheet_name='Filmes Estr BB')\n",
    "seriesEstr_BB_limpo = pd.read_excel(arquivo, sheet_name='S√©ries Estr BB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f8a52-f718-4eba-8529-3321a1b07277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_headers(df):\n",
    "    df.columns = (df.columns.astype(str)\n",
    "                  .str.replace('\\u00A0', ' ', regex=False)   # NBSP\n",
    "                  .str.replace('\\ufeff', '', regex=False)    # BOM\n",
    "                  .str.replace(r'\\s+', ' ', regex=True)      # espa√ßos duplicados\n",
    "                  .str.strip())\n",
    "    return df\n",
    "\n",
    "for df in [filmesBR_BB_limpo, seriesBR_BB_limpo, filmesEstr_BB_limpo, seriesEstr_BB_limpo,\n",
    "           filmesBR_SAD_limpo, seriesBR_SAD_limpo]:\n",
    "    _fix_headers(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c24491-6872-4102-86b0-ebcaabf87578",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_bb = [\n",
    "    'BB UID','BB Year','BB Directors','BB Primary Company','BB Production Companies',\n",
    "    'BB Title_processado','BB Original Title_processado','Platform Title_processado'\n",
    "]\n",
    "\n",
    "for name, d in {\n",
    "    'filmesBR_BB_limpo': filmesBR_BB_limpo,\n",
    "    'seriesBR_BB_limpo': seriesBR_BB_limpo,\n",
    "    'filmesEstr_BB_limpo': filmesEstr_BB_limpo,\n",
    "    'seriesEstr_BB_limpo': seriesEstr_BB_limpo,\n",
    "}.items():\n",
    "    missing = [c for c in required_bb if c not in d.columns]\n",
    "    if missing:\n",
    "        print(f\"{name} faltando:\", missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761887e7",
   "metadata": {},
   "source": [
    "## 4) Busca de Correspond√™ncias exatas de T√≠tulo, Diretor e Ano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4e918",
   "metadata": {},
   "source": [
    "### 4.1) Defini√ß√£o de fun√ß√µes de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e1f30-6b4b-4e92-a391-a759650a6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4.1 Fun√ß√µes ‚Äî motor de match limpo (t√≠tulo =, ano ¬±2, diretor obrigat√≥rio)\n",
    "# ================================================================\n",
    "\n",
    "ANO_TOL = 2  # toler√¢ncia\n",
    "\n",
    "def _cpb_col(df):\n",
    "    return 'N¬∫ CPB' if 'N¬∫ CPB' in df.columns else ('N¬∞ CPB' if 'N¬∞ CPB' in df.columns else 'N¬∫ CPB')\n",
    "\n",
    "def build_bb_title_keys(df_bb):\n",
    "    title_cols = [\n",
    "        'BB Title_processado',\n",
    "        'BB Original Title_processado',\n",
    "        'Platform Title_processado'\n",
    "    ]\n",
    "    keep = [\n",
    "        'BB UID','BB Year','BB Directors',\n",
    "        'BB Primary Company','BB Production Companies',\n",
    "        # >>> campos processados que faltavam <<<\n",
    "        'BB Primary Company_processado','BB Production Companies_processado',\n",
    "        'BB Title','BB Original Title','Platform Title'\n",
    "    ]\n",
    "    m = df_bb[keep + title_cols].melt(\n",
    "        id_vars=keep,\n",
    "        value_vars=title_cols,\n",
    "        var_name='title_source',\n",
    "        value_name='BB_title_key'\n",
    "    )\n",
    "    m = m[m['BB_title_key'].notna() & (m['BB_title_key'] != '')]\n",
    "    m = m.drop_duplicates(['BB UID','BB_title_key'], keep='first')\n",
    "    return m\n",
    "\n",
    "\n",
    "def match_pair_min(df_sad, df_bb, categoria):\n",
    "    cpb = _cpb_col(df_sad)\n",
    "\n",
    "    # 1) t√≠tulo\n",
    "    bbk = build_bb_title_keys(df_bb)\n",
    "    sadk = df_sad[[cpb, 'T√≠tulo Original','T√≠tulo Original_processado',\n",
    "                   'Diretor','Ano Inicial','Ano Final','Produtora']].copy()\n",
    "    cand = bbk.merge(sadk, left_on='BB_title_key', right_on='T√≠tulo Original_processado', how='inner')\n",
    "\n",
    "    # 2) ano ¬±2\n",
    "    cand = cand.dropna(subset=['BB Year','Ano Inicial']).copy()\n",
    "    cand['Ano Final'] = cand['Ano Final'].fillna(cand['Ano Inicial'])\n",
    "    mask_ano = (\n",
    "        (cand['BB Year'].astype(int) >= (cand['Ano Inicial'].astype(int) - ANO_TOL)) &\n",
    "        (cand['BB Year'].astype(int) <= (cand['Ano Final'].astype(int)   + ANO_TOL))\n",
    "    )\n",
    "    cand = cand[mask_ano]\n",
    "\n",
    "    # 3) diretor obrigat√≥rio\n",
    "    a = cand['BB Directors'].apply(surnames_from_raw)\n",
    "    b = cand['Diretor'].apply(surnames_from_raw)\n",
    "    cand['dir_overlap'] = [sorted(list(x & y)) for x, y in zip(a, b)]\n",
    "    cand = cand[cand['dir_overlap'].map(len) > 0].copy()\n",
    "\n",
    "    # 4) sa√≠da\n",
    "    out = cand[[cpb, 'BB UID',\n",
    "                'T√≠tulo Original',\n",
    "                'BB Title','BB Original Title','Platform Title',\n",
    "                'Diretor','BB Directors',\n",
    "                'Ano Inicial','Ano Final','BB Year',\n",
    "                'Produtora','BB Primary Company','BB Production Companies']].copy()\n",
    "\n",
    "    out['categoria']  = categoria\n",
    "    out['match_rule'] = 'titulo+ano+diretor'\n",
    "    out = out.rename(columns={'BB UID':'UID', 'BB Title':'Title',\n",
    "                              'BB Directors':'Directors', 'BB Year':'Year',\n",
    "                              cpb: cpb})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4834ac-3af4-47fb-aef2-b46536777aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4.1b ‚Äî regra 2: t√≠tulo =, ano ¬±2, PRODUTORA (tokens) obrigat√≥ria\n",
    "# ================================================================\n",
    "\n",
    "def _bb_prod_tokens_row(r):\n",
    "    s1 = str(r.get('BB Primary Company_processado', '') or '').strip()\n",
    "    s2 = str(r.get('BB Production Companies_processado', '') or '').strip()\n",
    "    toks = set()\n",
    "    if s1:\n",
    "        toks |= tokens_empresas(s1)\n",
    "    if s2 and s2 != s1:\n",
    "        toks |= tokens_empresas(s2)\n",
    "    return toks\n",
    "\n",
    "def match_pair_produtora(df_sad, df_bb, categoria):\n",
    "    cpb = _cpb_col(df_sad)\n",
    "\n",
    "    # 1) t√≠tulo\n",
    "    bbk = build_bb_title_keys(df_bb)\n",
    "    sadk = df_sad[[cpb, 'T√≠tulo Original','T√≠tulo Original_processado',\n",
    "                   'Produtora','Produtora_processada',\n",
    "                   'Ano Inicial','Ano Final',\n",
    "                   'Diretor']].copy()  # diretor s√≥ para visualiza√ß√£o/auditoria\n",
    "    cand = bbk.merge(sadk, left_on='BB_title_key', right_on='T√≠tulo Original_processado', how='inner')\n",
    "\n",
    "    # 2) ano ¬±2\n",
    "    cand = cand.dropna(subset=['BB Year','Ano Inicial']).copy()\n",
    "    cand['Ano Final'] = cand['Ano Final'].fillna(cand['Ano Inicial'])\n",
    "    mask_ano = (\n",
    "        (cand['BB Year'].astype(int) >= (cand['Ano Inicial'].astype(int) - ANO_TOL)) &\n",
    "        (cand['BB Year'].astype(int) <= (cand['Ano Final'].astype(int)   + ANO_TOL))\n",
    "    )\n",
    "    cand = cand[mask_ano]\n",
    "\n",
    "    # 3) PRODUTORA ‚Äî overlap de tokens\n",
    "    cand['prod_bb']  = cand.apply(_bb_prod_tokens_row, axis=1)\n",
    "    cand['prod_sad'] = cand['Produtora_processada'].apply(tokens_empresas)\n",
    "    cand['prod_overlap'] = [sorted(list(x & y)) for x, y in zip(cand['prod_bb'], cand['prod_sad'])]\n",
    "    cand = cand[cand['prod_overlap'].map(len) > 0].copy()\n",
    "\n",
    "    # 4) sa√≠da\n",
    "    out = cand[[cpb, 'BB UID',\n",
    "                'T√≠tulo Original',\n",
    "                'BB Title','BB Original Title','Platform Title',\n",
    "                'Diretor','BB Directors',\n",
    "                'Ano Inicial','Ano Final','BB Year',\n",
    "                'Produtora','BB Primary Company','BB Production Companies']].copy()\n",
    "\n",
    "    out['categoria']  = categoria\n",
    "    out['match_rule'] = 'titulo+ano+produtora'\n",
    "    out = out.rename(columns={'BB UID':'UID', 'BB Title':'Title',\n",
    "                              'BB Directors':'Directors', 'BB Year':'Year',\n",
    "                              cpb: cpb})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f29d8-c886-4a3b-892c-d6152bc2f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4.2 ‚Äî Executar PRODUTORA e unir com DIRETOR (prioridade ao DIRETOR)\n",
    "# ================================================================\n",
    "\n",
    "# Se voc√™ j√° rodou a 1¬™ rodada e tem out_* da regra diretor, mantenha:\n",
    "dir_filmes_BR   = match_pair_min(filmesBR_SAD_limpo,  filmesBR_BB_limpo,   'filmes_BR')\n",
    "dir_series_BR   = match_pair_min(seriesBR_SAD_limpo,  seriesBR_BB_limpo,   'series_BR')\n",
    "dir_filmes_EST  = match_pair_min(filmesBR_SAD_limpo,  filmesEstr_BB_limpo, 'filmes_EST')\n",
    "dir_series_EST  = match_pair_min(seriesBR_SAD_limpo,  seriesEstr_BB_limpo, 'series_EST')\n",
    "\n",
    "matches_dir = pd.concat([dir_filmes_BR, dir_series_BR, dir_filmes_EST, dir_series_EST],\n",
    "                        ignore_index=True)\n",
    "\n",
    "# Filtrar os BB ainda n√£o casados para a rodada PRODUTORA (opcional, mas recomendado)\n",
    "uids_casados = set(matches_dir['UID'].unique())\n",
    "\n",
    "filmesBR_BB_rest   = filmesBR_BB_limpo[~filmesBR_BB_limpo['BB UID'].isin(uids_casados)]\n",
    "seriesBR_BB_rest   = seriesBR_BB_limpo[~seriesBR_BB_limpo['BB UID'].isin(uids_casados)]\n",
    "filmesEstr_BB_rest = filmesEstr_BB_limpo[~filmesEstr_BB_limpo['BB UID'].isin(uids_casados)]\n",
    "seriesEstr_BB_rest = seriesEstr_BB_limpo[~seriesEstr_BB_limpo['BB UID'].isin(uids_casados)]\n",
    "\n",
    "prod_filmes_BR   = match_pair_produtora(filmesBR_SAD_limpo,  filmesBR_BB_rest,   'filmes_BR')\n",
    "prod_series_BR   = match_pair_produtora(seriesBR_SAD_limpo,  seriesBR_BB_rest,   'series_BR')\n",
    "prod_filmes_EST  = match_pair_produtora(filmesBR_SAD_limpo,  filmesEstr_BB_rest, 'filmes_EST')\n",
    "prod_series_EST  = match_pair_produtora(seriesBR_SAD_limpo,  seriesEstr_BB_rest, 'series_EST')\n",
    "\n",
    "matches_prod = pd.concat([prod_filmes_BR, prod_series_BR, prod_filmes_EST, prod_series_EST],\n",
    "                         ignore_index=True)\n",
    "\n",
    "# Uni√£o final: DIRETOR tem prioridade; depois PRODUTORA completa o que faltou\n",
    "# (se preferir, pode trocar 'keep=\"first\"' por 'keep=\"last\"' invertendo a prioridade)\n",
    "cpb_col = 'N¬∫ CPB' if 'N¬∫ CPB' in filmesBR_SAD_limpo.columns else 'N¬∞ CPB'\n",
    "matches_all = pd.concat([matches_dir, matches_prod], ignore_index=True)\n",
    "matches_all = matches_all.drop_duplicates(subset=['UID', cpb_col], keep='first')\n",
    "\n",
    "# Contagens\n",
    "print(\"Contagens por categoria (ap√≥s uni√£o):\")\n",
    "print(matches_all.groupby(['categoria','match_rule']).size().unstack(fill_value=0))\n",
    "print(\"\\nUIDs √∫nicos casados (total):\", matches_all['UID'].nunique())\n",
    "print(\"CPBs √∫nicos casados (total):\", matches_all[cpb_col].nunique())\n",
    "\n",
    "# Amostra para inspe√ß√£o\n",
    "display(matches_all.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b079ac2-0cbe-465c-892f-af2c715069fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4.3 Resultados ‚Äî contagens e amostra\n",
    "# ================================================================\n",
    "\n",
    "print(\"Pares por categoria:\")\n",
    "print(matches_all['categoria'].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"UIDs √∫nicos casados:\", matches_all['UID'].nunique())\n",
    "print(\"CPBs √∫nicos casados:\", matches_all['N¬∫ CPB'].nunique(), \"\\n\")  # ajuste p/ 'N¬∞ CPB' se for o seu caso\n",
    "\n",
    "display(matches_all.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab019fd-1c34-44bb-b5ad-b5de5b8cc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Sumariza√ß√£o por categoria com PRODUTORA (+ ganhos novos)\n",
    "# Requer: matches_dir, matches_prod, build_bb_title_keys, surnames_from_raw,\n",
    "#         tokens_empresas, _bb_prod_tokens_row (definidas antes)\n",
    "# ================================================================\n",
    "\n",
    "def funil_uid_com_prod(df_sad, df_bb, categoria, matches_dir, matches_prod):\n",
    "    # base = UIDs √∫nicos do BB\n",
    "    obras = df_bb['BB UID'].nunique()\n",
    "\n",
    "    # --- t√≠tulo (sem ano) ---\n",
    "    bbk  = build_bb_title_keys(df_bb)\n",
    "    sadk = df_sad[['T√≠tulo Original_processado', 'Diretor',\n",
    "                   'Produtora_processada', 'Ano Inicial', 'Ano Final']].copy()\n",
    "    e_title = bbk.merge(sadk, left_on='BB_title_key',\n",
    "                        right_on='T√≠tulo Original_processado', how='inner')\n",
    "\n",
    "    uids_titulo = set(e_title['BB UID'].unique())\n",
    "    n_titulo = len(uids_titulo)\n",
    "\n",
    "    # --- diretor (sem ano) ---\n",
    "    a = e_title['BB Directors'].apply(surnames_from_raw)\n",
    "    b = e_title['Diretor'].apply(surnames_from_raw)\n",
    "    dir_ok = [len(x & y) > 0 for x, y in zip(a, b)]\n",
    "    uids_dir = set(e_title[dir_ok]['BB UID'].unique())\n",
    "    n_dir = len(uids_dir)\n",
    "\n",
    "    # --- produtora (sem ano) ---\n",
    "    prod_bb  = e_title.apply(_bb_prod_tokens_row, axis=1)\n",
    "    prod_sad = e_title['Produtora_processada'].apply(tokens_empresas)\n",
    "    prod_ok  = [len(x & y) > 0 for x, y in zip(prod_bb, prod_sad)]\n",
    "    uids_prod = set(e_title[prod_ok]['BB UID'].unique())\n",
    "    n_prod = len(uids_prod)\n",
    "\n",
    "    # --- finais por regra (j√° com ano) a partir das sa√≠das de cada regra ---\n",
    "    u_dir_final  = set(matches_dir.loc[matches_dir['categoria']==categoria, 'UID'].unique())\n",
    "    u_prod_final = set(matches_prod.loc[matches_prod['categoria']==categoria, 'UID'].unique())\n",
    "\n",
    "    final_total_uids   = u_dir_final | u_prod_final\n",
    "    novos_via_produtor = u_prod_final - u_dir_final\n",
    "\n",
    "    # convers√µes\n",
    "    conv_total_titulo   = (n_titulo / obras * 100) if obras else 0.0\n",
    "    conv_tit_dir        = (n_dir    / n_titulo * 100) if n_titulo else 0.0\n",
    "    conv_tit_prod       = (n_prod   / n_titulo * 100) if n_titulo else 0.0\n",
    "    conv_total          = (len(final_total_uids) / obras * 100) if obras else 0.0\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'categoria': categoria,\n",
    "        'obras': obras,\n",
    "        'regra_titulo': n_titulo,\n",
    "        'regra_diretor': n_dir,\n",
    "        'regra_produtora': n_prod,\n",
    "        'final_dir_ano': len(u_dir_final),\n",
    "        'final_prod_ano': len(u_prod_final),\n",
    "        'final_total': len(final_total_uids),\n",
    "        'novos_via_produtora': len(novos_via_produtor),\n",
    "        'conv_total_titulo_%': round(conv_total_titulo, 2),\n",
    "        'conv_titulo‚Üídiretor_%': round(conv_tit_dir, 2),\n",
    "        'conv_titulo‚Üíprodutora_%': round(conv_tit_prod, 2),\n",
    "        'conv_total_%': round(conv_total, 2),\n",
    "    }])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0899cb-33f4-4c91-a765-8d4a2e6a4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Rodar por categoria ----\n",
    "sum_f_br = funil_uid_com_prod(filmesBR_SAD_limpo,  filmesBR_BB_limpo,   'filmes_BR',  matches_dir, matches_prod)\n",
    "sum_s_br = funil_uid_com_prod(seriesBR_SAD_limpo,  seriesBR_BB_limpo,   'series_BR',  matches_dir, matches_prod)\n",
    "sum_f_es = funil_uid_com_prod(filmesBR_SAD_limpo,  filmesEstr_BB_limpo, 'filmes_EST', matches_dir, matches_prod)\n",
    "sum_s_es = funil_uid_com_prod(seriesBR_SAD_limpo,  seriesEstr_BB_limpo, 'series_EST', matches_dir, matches_prod)\n",
    "\n",
    "sum_cat = pd.concat([sum_f_br, sum_s_br, sum_f_es, sum_s_es], ignore_index=True)\n",
    "\n",
    "# ---- Global (somando categorias) ----\n",
    "glob = pd.DataFrame([{\n",
    "    'obras':            sum_cat['obras'].sum(),\n",
    "    'regra_titulo':     sum_cat['regra_titulo'].sum(),\n",
    "    'regra_diretor':    sum_cat['regra_diretor'].sum(),\n",
    "    'regra_produtora':  sum_cat['regra_produtora'].sum(),\n",
    "    'final_dir_ano':    sum_cat['final_dir_ano'].sum(),\n",
    "    'final_prod_ano':   sum_cat['final_prod_ano'].sum(),\n",
    "    'final_total':      sum_cat['final_total'].sum(),\n",
    "    'novos_via_produtora': sum_cat['novos_via_produtora'].sum()\n",
    "}])\n",
    "\n",
    "glob['conv_total_titulo_%']    = (glob['regra_titulo']   / glob['obras'] * 100).round(2)\n",
    "glob['conv_titulo‚Üídiretor_%']  = (glob['regra_diretor']  / glob['regra_titulo'] * 100).round(2)\n",
    "glob['conv_titulo‚Üíprodutora_%']= (glob['regra_produtora']/ glob['regra_titulo'] * 100).round(2)\n",
    "glob['conv_total_%']           = (glob['final_total']    / glob['obras'] * 100).round(2)\n",
    "\n",
    "# ---- Exibir ----\n",
    "fmt = {\n",
    "    'conv_total_titulo_%':'{:.2f}%',\n",
    "    'conv_titulo‚Üídiretor_%':'{:.2f}%',\n",
    "    'conv_titulo‚Üíprodutora_%':'{:.2f}%',\n",
    "    'conv_total_%':'{:.2f}%'\n",
    "}\n",
    "print(\"Resumo por categoria (com produtora):\")\n",
    "display(sum_cat.style.format(fmt))\n",
    "\n",
    "print(\"\\nResumo global:\")\n",
    "display(glob.style.format(fmt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d3270-d944-476e-80fe-071bd1b42a54",
   "metadata": {},
   "source": [
    "## 5 ) Exports para Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132c908-9581-4006-b7dc-e3f44b5749b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ETAPA 1 ‚Äî Consolidar resultado final e salvar auditoria\n",
    "# Requer j√° existirem: matches_dir, matches_prod\n",
    "# ================================================================\n",
    "\n",
    "# 1) escolher o nome da coluna CPB conforme sua base (N¬∫ CPB ou N¬∞ CPB)\n",
    "cpb_col = 'N¬∫ CPB' if 'N¬∫ CPB' in filmesBR_SAD_limpo.columns else 'N¬∞ CPB'\n",
    "\n",
    "# 2) uni√£o (prioridade ao DIRETOR; o concat mant√©m a ordem: dir -> prod)\n",
    "matches_all = pd.concat([matches_dir, matches_prod], ignore_index=True)\n",
    "matches_all = matches_all.drop_duplicates(subset=['UID', cpb_col], keep='first')\n",
    "\n",
    "# 3) ordenar e selecionar colunas para vis√£o lado a lado\n",
    "cols_auditoria = [\n",
    "    cpb_col, 'UID',\n",
    "    'T√≠tulo Original', 'Title', 'BB Original Title', 'Platform Title',\n",
    "    'Diretor', 'Directors',\n",
    "    'Ano Inicial', 'Ano Final', 'Year',\n",
    "    'Produtora', 'BB Primary Company', 'BB Production Companies',\n",
    "    'categoria', 'match_rule'\n",
    "]\n",
    "# mant√©m colunas que existem; evita KeyError caso alguma n√£o esteja presente\n",
    "cols_auditoria = [c for c in cols_auditoria if c in matches_all.columns]\n",
    "\n",
    "matches_all = matches_all[cols_auditoria].sort_values(\n",
    "    by=['categoria', 'match_rule', 'Title' if 'Title' in matches_all.columns else cpb_col]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# 4) resumos\n",
    "resumo_categoria = (\n",
    "    matches_all\n",
    "      .groupby('categoria')\n",
    "      .agg(pares=('UID', 'size'),\n",
    "           uids=('UID', 'nunique'),\n",
    "           cpbs=(cpb_col, 'nunique'))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "resumo_por_regra = (\n",
    "    matches_all\n",
    "      .groupby(['categoria', 'match_rule'])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Resumo por categoria:\")\n",
    "display(resumo_categoria)\n",
    "\n",
    "print(\"\\nResumo por regra:\")\n",
    "display(resumo_por_regra)\n",
    "\n",
    "# 5) salvar Excel de auditoria\n",
    "arquivo_auditoria = 'Auditoria - matches consolidado.xlsx'\n",
    "with pd.ExcelWriter(arquivo_auditoria, engine='openpyxl') as writer:\n",
    "    matches_all.to_excel(writer, sheet_name='consolidado', index=False)\n",
    "    resumo_categoria.to_excel(writer, sheet_name='resumo_categoria', index=False)\n",
    "    resumo_por_regra.to_excel(writer, sheet_name='resumo_regra', index=False)\n",
    "\n",
    "print(f\"\\nArquivo salvo: {arquivo_auditoria}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c1990-60c9-4924-9e50-144c6b886f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ETAPA 2 ‚Äî Materializar est√°gios (por categoria) e exportar\n",
    "# Requer: build_bb_title_keys, surnames_from_raw, tokens_empresas,\n",
    "#         _bb_prod_tokens_row, e os DFs *_SAD_limpo / *_BB_limpo\n",
    "# ================================================================\n",
    "\n",
    "cpb_col = 'N¬∫ CPB' if 'N¬∫ CPB' in filmesBR_SAD_limpo.columns else 'N¬∞ CPB'\n",
    "ANO_TOL = 2\n",
    "\n",
    "def materializar_estagios(df_sad, df_bb, categoria):\n",
    "    # 0) base por t√≠tulo\n",
    "    bbk = build_bb_title_keys(df_bb)\n",
    "    sadk = df_sad[[cpb_col, 'T√≠tulo Original', 'T√≠tulo Original_processado',\n",
    "                   'Diretor', 'Produtora', 'Produtora_processada',\n",
    "                   'Ano Inicial', 'Ano Final']].copy()\n",
    "    base = bbk.merge(sadk, left_on='BB_title_key', right_on='T√≠tulo Original_processado', how='inner')\n",
    "\n",
    "    # est√°gio 1 ‚Äî s√≥ T√çTULO\n",
    "    cols_view = [cpb_col, 'BB UID', 'T√≠tulo Original',\n",
    "                 'BB Title','BB Original Title','Platform Title',\n",
    "                 'Diretor','BB Directors',\n",
    "                 'Produtora','BB Primary Company','BB Production Companies',\n",
    "                 'Ano Inicial','Ano Final','BB Year']\n",
    "    titulo_matched = base[cols_view].rename(columns={'BB UID':'UID', 'BB Title':'Title', 'BB Year':'Year'})\n",
    "\n",
    "    # est√°gio 2 ‚Äî T√çTULO + DIRETOR (sem ano)\n",
    "    a = base['BB Directors'].apply(surnames_from_raw)\n",
    "    b = base['Diretor'].apply(surnames_from_raw)\n",
    "    dir_ok = [len(x & y) > 0 for x, y in zip(a, b)]\n",
    "    titulo_diretor_matched = titulo_matched[dir_ok].copy()\n",
    "\n",
    "    # est√°gio 3 ‚Äî T√çTULO + PRODUTORA (sem ano)\n",
    "    prod_bb  = base.apply(_bb_prod_tokens_row, axis=1)\n",
    "    prod_sad = base['Produtora_processada'].apply(tokens_empresas)\n",
    "    prod_ok  = [len(x & y) > 0 for x, y in zip(prod_bb, prod_sad)]\n",
    "    titulo_produtora_matched = titulo_matched[prod_ok].copy()\n",
    "\n",
    "    # helper ano ¬± tol\n",
    "    def filtrar_ano(df):\n",
    "        if df.empty: \n",
    "            return df\n",
    "        df = df.dropna(subset=['Ano Inicial']).copy()\n",
    "        df['Ano Final'] = df['Ano Final'].fillna(df['Ano Inicial'])\n",
    "        mask = (\n",
    "            (df['Year'].astype(int) >= (df['Ano Inicial'].astype(int) - ANO_TOL)) &\n",
    "            (df['Year'].astype(int) <= (df['Ano Final'].astype(int)   + ANO_TOL))\n",
    "        )\n",
    "        return df[mask]\n",
    "\n",
    "    # est√°gio 4 ‚Äî FINAL (t√≠tulo + diretor + ano)\n",
    "    final_dir_ano  = filtrar_ano(titulo_diretor_matched).copy()\n",
    "\n",
    "    # est√°gio 5 ‚Äî FINAL (t√≠tulo + produtora + ano)\n",
    "    final_prod_ano = filtrar_ano(titulo_produtora_matched).copy()\n",
    "\n",
    "    # metadados\n",
    "    for df in [titulo_matched, titulo_diretor_matched, titulo_produtora_matched, final_dir_ano, final_prod_ano]:\n",
    "        df['categoria'] = categoria\n",
    "\n",
    "    return {\n",
    "        'titulo_matched': titulo_matched,\n",
    "        'titulo_diretor_matched': titulo_diretor_matched,\n",
    "        'titulo_produtora_matched': titulo_produtora_matched,\n",
    "        'final_dir_ano': final_dir_ano,\n",
    "        'final_prod_ano': final_prod_ano\n",
    "    }\n",
    "\n",
    "# ---- rodar para os 4 pares ----\n",
    "st_filmes_BR  = materializar_estagios(filmesBR_SAD_limpo,  filmesBR_BB_limpo,   'filmes_BR')\n",
    "st_series_BR  = materializar_estagios(seriesBR_SAD_limpo,  seriesBR_BB_limpo,   'series_BR')\n",
    "st_filmes_EST = materializar_estagios(filmesBR_SAD_limpo,  filmesEstr_BB_limpo, 'filmes_EST')\n",
    "st_series_EST = materializar_estagios(seriesBR_SAD_limpo,  seriesEstr_BB_limpo, 'series_EST')\n",
    "\n",
    "# ---- exportar\n",
    "arq_estagios = 'Auditoria - est√°gios por categoria.xlsx'\n",
    "with pd.ExcelWriter(arq_estagios, engine='openpyxl') as wr:\n",
    "    for prefixo, st in [\n",
    "        ('filmes_BR',  st_filmes_BR),\n",
    "        ('series_BR',  st_series_BR),\n",
    "        ('filmes_EST', st_filmes_EST),\n",
    "        ('series_EST', st_series_EST),\n",
    "    ]:\n",
    "        st['titulo_matched'].to_excel(wr, sheet_name=f'{prefixo} - t√≠tulo', index=False)\n",
    "        st['titulo_diretor_matched'].to_excel(wr, sheet_name=f'{prefixo} - t√≠tulo+diretor', index=False)\n",
    "        st['titulo_produtora_matched'].to_excel(wr, sheet_name=f'{prefixo} - t√≠tulo+prod', index=False)\n",
    "        st['final_dir_ano'].to_excel(wr, sheet_name=f'{prefixo} - final dir', index=False)\n",
    "        st['final_prod_ano'].to_excel(wr, sheet_name=f'{prefixo} - final prod', index=False)\n",
    "\n",
    "print(f'Arquivo salvo: {arq_estagios}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760e07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ceb079",
   "metadata": {},
   "source": [
    "### 4.3) Elimina plataformas sem interesse em buscas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF completo e coluna de plataforma para o join\n",
    "df_completo_plataformas = Base_BB\n",
    "col_plataforma = 'Platform Name'\n",
    "\n",
    "# Plataformas a excluir (lista)\n",
    "PLATAFORMAS_EXCLUIR = [\n",
    "    '99 Media',    'AFA Play',    'ALTBalaji',    'American Indian Film Gallery',    'Amazon Prime Video',    'Anime Onegai',    'AppleTV',     'Apple TV+',    'Archivio Luce',    'AXN',    'BroadwayHD',\n",
    "    'CINE.AR PLAY',    'Canela.TV',    'Cindie',    'Claro TV+',    'Claro Video',    ' CirqueConnect',    'Combate',    'Crunchyroll',    'Cultpix',    'Curiosity Stream',    'DaFilms',    'DAZN',\n",
    "    'Dekkoo',    'Demand Africa',    'Digital Concert Hall',    'Digital Theatre',    'Disney+',    'DOCSVILLE',    'Eventive',    'F1 TV',    'Fanatiz',    'FIFA+',    'Filmbox+',    'Filmzie',\n",
    "    'FlixOl√©',    'Globoplay',    'Globe Player',    'GuideDoc',    'HENRI',    'HispanTV',    'History Hit',    'Hoichoi',    'IFI Archive Player',    'IndieFlix',    'iQIYI',    'IWantTFC',    'Kidoodle.TV',\n",
    "    'KINOA.TV',    'KOCOWA+',    'KweliTV',    'Looke',    'Max',    'MagellanTV',    'Marquee TV',    'Means TV',    'Mercado Play',    'Met Opera on Demand',    'MLB.TV',    'MovieSaints',    'MUBI',\n",
    "    'NBA League Pass',    'Nebula',    'Netflix',    'OCULTO.TV',    'Oldflix',    'OnDemandKorea',    'OperaVision',    'Paramount+',    'Plex',    'Pluto TV',    'Qello Concerts',    'Rakuten Viki',\n",
    "    'Reel Short',    'Retina Latina',    'Revry',    'RT en Espa√±ol',    'Selecta TV',    'ShemarooMe',    'Simply South',    'Sky+',    'Sony Channel',    'Tamandu√° TV',    'Teatrix',    'Toon Goggles',\n",
    "    'Troma NOW!',    'TV Cai√ßara',    'TVN Play',    'Umbra',    'UNIVER VIDEO',    'Universal+',    'Viddsee',    'Vivo Play',    'Watch',    'WOW Presents Plus',    'YouTube',    'YouTube Premium',    'Zee5',\n",
    "]\n",
    "\n",
    "# (opcional) conjunto para checagens/membership r√°pidas\n",
    "PLATAFORMAS_EXCLUIR_SET = set(PLATAFORMAS_EXCLUIR)\n",
    "\n",
    "print(\"Total plataformas a excluir:\", len(PLATAFORMAS_EXCLUIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e17a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Filas de revis√£o: estrangeiras com country vazio, diretor presente,\n",
    "# mapeando plataformas a partir do DF completo (n√£o deduplicado)\n",
    "# Par√¢metros que voc√™ PRECISA definir antes:\n",
    "#   PLATAFORMAS_EXCLUIR = [...]\n",
    "#   df_completo_plataformas = <seu DF completo, sem deduplicar por UID>\n",
    "#   col_plataforma = 'Platform Name'  # ajuste se necess√°rio\n",
    "# ================================================================\n",
    "\n",
    "# -------- par√¢metros do usu√°rio --------\n",
    "PLATAFORMAS_EXCLUIR\n",
    "df_completo_plataformas = Base_BB_import\n",
    "col_plataforma = 'Platform Name'\n",
    "\n",
    "# -------- checagens expl√≠citas (sem try/except silencioso) --------\n",
    "if 'BB UID' not in df_completo_plataformas.columns:\n",
    "    raise KeyError(\"O DF completo informado N√ÉO tem a coluna 'BB UID'.\")\n",
    "if col_plataforma not in df_completo_plataformas.columns:\n",
    "    raise KeyError(f\"O DF completo informado N√ÉO tem a coluna '{col_plataforma}'.\")\n",
    "\n",
    "# -------- mapeia UID -> plataformas (excluindo as indesejadas) --------\n",
    "f_plat = df_completo_plataformas.copy()\n",
    "\n",
    "# normaliza plataforma (string) e elimina vazios\n",
    "f_plat[col_plataforma] = f_plat[col_plataforma].astype(str).str.strip()\n",
    "f_plat = f_plat[f_plat[col_plataforma] != '']\n",
    "\n",
    "# remove plataformas indesejadas\n",
    "mask_keep = ~f_plat[col_plataforma].isin(PLATAFORMAS_EXCLUIR)\n",
    "f_plat = f_plat[mask_keep]\n",
    "\n",
    "uid_to_plats = (\n",
    "    f_plat.groupby('BB UID', as_index=False)[col_plataforma]\n",
    "          .agg(lambda s: ' | '.join(sorted(set(s))))\n",
    "          .rename(columns={col_plataforma: 'Plataformas'})\n",
    ")\n",
    "\n",
    "# -------- obt√©m UIDs j√° casados para excluir da revis√£o --------\n",
    "cpb_col = 'N¬∫ CPB' if 'N¬∫ CPB' in filmesBR_SAD_limpo.columns else 'N¬∞ CPB'\n",
    "uids_casados = set(matches_all['UID'].unique())\n",
    "\n",
    "# -------- fun√ß√£o para gerar fila (filmes/s√©ries estrangeiras) --------\n",
    "def fila_revisao_estr(df_estr, categoria_label):\n",
    "    if 'BB Countries' not in df_estr.columns:\n",
    "        raise KeyError(f\"O DF '{categoria_label}' n√£o tem a coluna 'BB Countries'.\")\n",
    "    if 'BB Directors' not in df_estr.columns:\n",
    "        raise KeyError(f\"O DF '{categoria_label}' n√£o tem a coluna 'BB Directors'.\")\n",
    "\n",
    "    # country vazio + diretor presente\n",
    "    base = df_estr[\n",
    "        (df_estr['BB Countries'].isna()) &\n",
    "        (df_estr['BB Directors'].astype(str).str.strip() != '')\n",
    "    ].copy()\n",
    "\n",
    "    # remove os que j√° casaram\n",
    "    base = base[~base['BB UID'].isin(uids_casados)].copy()\n",
    "\n",
    "    # junta plataformas a partir do DF completo\n",
    "    out = base.merge(uid_to_plats, on='BB UID', how='left')\n",
    "\n",
    "    # mantemos apenas quem de fato tem plataforma (ap√≥s exclus√£o)\n",
    "    out = out[out['Plataformas'].notna() & (out['Plataformas'].str.strip() != '')].copy()\n",
    "\n",
    "    # colunas √∫teis para revis√£o\n",
    "    cols = [c for c in [\n",
    "        'BB UID', 'BB Title', 'BB Original Title', 'BB Year',\n",
    "        'BB Directors', 'BB Countries',\n",
    "        'Plataformas'\n",
    "    ] if c in out.columns]\n",
    "\n",
    "    out = out[cols].sort_values(['Plataformas','BB Year','BB Title'], na_position='last')\n",
    "    out['categoria'] = categoria_label\n",
    "    return out\n",
    "\n",
    "# -------- gerar filas para filmes/s√©ries estrangeiras --------\n",
    "revisao_filmes_EST  = fila_revisao_estr(filmesEstr_BB_limpo, 'filmes_EST')\n",
    "revisao_series_EST  = fila_revisao_estr(seriesEstr_BB_limpo, 'series_EST')\n",
    "\n",
    "print(\"Resumo das filas de revis√£o:\")\n",
    "print(\"filmes_EST:\", len(revisao_filmes_EST))\n",
    "print(\"series_EST:\", len(revisao_series_EST))\n",
    "\n",
    "# -------- exportar para Excel --------\n",
    "arq_revisao = 'Revisao - estr sem country (por plataformas).xlsx'\n",
    "with pd.ExcelWriter(arq_revisao, engine='openpyxl') as wr:\n",
    "    revisao_filmes_EST.to_excel(wr, sheet_name='filmes_EST', index=False)\n",
    "    revisao_series_EST.to_excel(wr, sheet_name='series_EST', index=False)\n",
    "print(f\"Arquivo salvo: {arq_revisao}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497d111-85c0-4130-a382-f78e028d91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Listas de N√ÉO-MATCH para revis√£o\n",
    "#  - Estrg (filmes/s√©ries): por plataformas-alvo, diretor presente, n√£o casados\n",
    "#  - BR   (filmes/s√©ries):  BB Countries cont√©m \"BR\", n√£o casados\n",
    "#  Usa Base_BB (completo) para mapear UID -> plataformas e 1¬∫ deeplink\n",
    "# ================================================================\n",
    "\n",
    "PLATAFORMAS_ALVO = [\n",
    "    'Filmicca','Amaz√¥niaFLIX','TV Brasil Play','UOL Play',\n",
    "    'Cine Humberto Mauro Mais','Reserva Imovision','Curta!On','Cinemateca Pernambucana',\n",
    "]\n",
    "\n",
    "def _uid_col(df):\n",
    "    return 'BB UID' if 'BB UID' in df.columns else 'UID'\n",
    "\n",
    "# ---------------- Checagens m√≠nimas ----------------\n",
    "for name, df in [\n",
    "    ('Base_BB_import', Base_BB_import),\n",
    "    ('filmesBR_BB_limpo', filmesBR_BB_limpo),\n",
    "    ('seriesBR_BB_limpo', seriesBR_BB_limpo),\n",
    "    ('filmesEstr_BB_limpo', filmesEstr_BB_limpo),\n",
    "    ('seriesEstr_BB_limpo', seriesEstr_BB_limpo),\n",
    "]:\n",
    "    if _uid_col(df) not in df.columns:\n",
    "        raise KeyError(f\"{name} n√£o tem coluna de UID ('BB UID' ou 'UID').\")\n",
    "\n",
    "if 'Platform Name' not in Base_BB_import.columns or 'Deeplink' not in Base_BB_import.columns:\n",
    "    raise KeyError(\"Base_BB_import precisa de 'Platform Name' e 'Deeplink'.\")\n",
    "\n",
    "# ---------------- UIDs j√° casados (para excluir) ----------------\n",
    "uids_casados = set(matches_all[_uid_col(matches_all)].unique())\n",
    "\n",
    "# ---------------- Mapa UID -> plataformas-alvo + 1¬∫ deeplink ----------------\n",
    "uid_full = _uid_col(Base_BB_import)\n",
    "bb_plat_keep = Base_BB_import[[uid_full,'Platform Name','Deeplink']].copy()\n",
    "bb_plat_keep = bb_plat_keep[bb_plat_keep['Platform Name'].isin(PLATAFORMAS_ALVO)]\n",
    "\n",
    "uid_to_plats = (\n",
    "    bb_plat_keep.sort_values(['Platform Name'])\n",
    "    .groupby(uid_full, as_index=False)\n",
    "    .agg({\n",
    "        'Platform Name': lambda s: ' | '.join(sorted(set(s))),\n",
    "        'Deeplink': 'first'\n",
    "    })\n",
    "    .rename(columns={'Platform Name': 'Plataformas', 'Deeplink': 'Deeplink_1'})\n",
    ")\n",
    "\n",
    "# ---------------- Fun√ß√µes can√¥nicas para montar as listas ----------------\n",
    "BASE_COLS = [\n",
    "    'BB Title','BB Original Title','BB Year',\n",
    "    'Seasons','Episodes','Season Numbers',\n",
    "    'BB Directors','BB Countries',\n",
    "    'BB Primary Company','BB Production Companies'\n",
    "]\n",
    "\n",
    "ORDER_COLS = ['Plataformas','BB Year','BB Title']  # para Estrg\n",
    "ORDER_COLS_BR = ['BB Year','BB Title']            # para BR\n",
    "\n",
    "def lista_estrg_por_plataforma(df_estr, categoria_label):\n",
    "    uidc = _uid_col(df_estr)\n",
    "    for c in BASE_COLS:\n",
    "        if c not in df_estr.columns:\n",
    "            raise KeyError(f\"{categoria_label}: coluna '{c}' ausente.\")\n",
    "\n",
    "    base = df_estr.copy()\n",
    "\n",
    "    # 1) n√£o casados\n",
    "    base = base[~base[uidc].isin(uids_casados)]\n",
    "\n",
    "    # 2) DIRETOR OBRIGAT√ìRIO\n",
    "    base = base[nonempty_str(base['BB Directors'])]\n",
    "\n",
    "    # 3) junta plataformas-alvo + deeplink (Left Join; depois mant√©m s√≥ quem achou plataforma-alvo)\n",
    "    out = base.merge(uid_to_plats, left_on=uidc, right_on=uid_full, how='left')\n",
    "    out = out[nonempty_str(out['Plataformas'])].copy()\n",
    "\n",
    "    cols = [uidc] + BASE_COLS + ['Plataformas','Deeplink_1']\n",
    "    out = out[cols].sort_values(ORDER_COLS, na_position='last')\n",
    "    out['categoria'] = categoria_label\n",
    "    return out\n",
    "\n",
    "def lista_br_sem_match(df_br, categoria_label):\n",
    "    uidc = _uid_col(df_br)\n",
    "    for c in BASE_COLS:\n",
    "        if c not in df_br.columns:\n",
    "            raise KeyError(f\"{categoria_label}: coluna '{c}' ausente.\")\n",
    "\n",
    "    base = df_br.copy()\n",
    "\n",
    "    # 1) n√£o casados\n",
    "    base = base[~base[uidc].isin(uids_casados)]\n",
    "\n",
    "    # 2) Country cont√©m \"BR\" (casos sem BR j√° foram para as listas Estrg)\n",
    "    base = base[base['BB Countries'].astype(str).str.contains('BR', case=False, na=False)]\n",
    "\n",
    "    out = base.merge(uid_to_plats, left_on=uidc, right_on=uid_full, how='left')\n",
    "    cols = [uidc] + BASE_COLS + ['Plataformas','Deeplink_1']\n",
    "    out = out[cols].sort_values(ORDER_COLS_BR, na_position='last')\n",
    "    out['categoria'] = categoria_label\n",
    "    return out\n",
    "\n",
    "# ---------------- Materializa√ß√£o (4 listas) ----------------\n",
    "estrg_filmes = lista_estrg_por_plataforma(filmesEstr_BB_limpo, 'Estrg Filmes')\n",
    "estrg_series = lista_estrg_por_plataforma(seriesEstr_BB_limpo, 'Estrg S√©ries')\n",
    "br_filmes    = lista_br_sem_match(filmesBR_BB_limpo, 'BR Filmes')\n",
    "br_series    = lista_br_sem_match(seriesBR_BB_limpo, 'BR S√©ries')\n",
    "\n",
    "# Diagn√≥stico r√°pido\n",
    "print(\"Resumo (linhas):\",\n",
    "      f\"Estrg Filmes={len(estrg_filmes)} | Estrg S√©ries={len(estrg_series)} | BR Filmes={len(br_filmes)} | BR S√©ries={len(br_series)}\")\n",
    "\n",
    "# ---------------- Export ----------------\n",
    "arq_listas = \"Revisao - NaoMatch (Estrg por plataforma + BR).xlsx\"\n",
    "with pd.ExcelWriter(arq_listas, engine='openpyxl') as wr:\n",
    "    estrg_filmes.to_excel(wr, sheet_name='Estrg Filmes', index=False)\n",
    "    estrg_series.to_excel(wr, sheet_name='Estrg S√©ries', index=False)\n",
    "    br_filmes.to_excel(wr,    sheet_name='BR Filmes',    index=False)\n",
    "    br_series.to_excel(wr,    sheet_name='BR S√©ries',    index=False)\n",
    "print(f\"Arquivo salvo: {arq_listas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22d2ba",
   "metadata": {},
   "source": [
    "## 5) Separa√ß√£o de listas de buscas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b10cd8",
   "metadata": {},
   "source": [
    "### 5.1) Importa√ß√£o dos resultados de match 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43471dd3",
   "metadata": {},
   "source": [
    "### 5.2) Separa√ß√£o dos dataframes de obras brasileiras das bases BB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152aae06",
   "metadata": {},
   "source": [
    "### 5.3) Modifica√ß√£o das dfs de obras brasileiras para gerar as listas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78099b5d",
   "metadata": {},
   "source": [
    "### 5.4) Cria√ß√£o das listas individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338af2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Listas finais de N√ÉO-MATCH para revis√£o manual\n",
    "#  - Estrg (filmes/s√©ries): sem CPB, pa√≠s vazio, diretor presente,\n",
    "#    e presentes nas plataformas foco (whitelist)\n",
    "#  - BR   (filmes/s√©ries): sem CPB e BB Countries contendo \"BR\"\n",
    "#  Join por BB UID na Base_BB_import para trazer Plataformas e Deeplink\n",
    "# ================================================================\n",
    "\n",
    "PLATAFORMAS_FOCO = [\n",
    "    'Filmicca',\n",
    "    'Amaz√¥niaFLIX',\n",
    "    'TV Brasil Play',\n",
    "    'UOL Play',\n",
    "    'Cine Humberto Mauro Mais',\n",
    "    'Reserva Imovision',\n",
    "    'Curta!On',\n",
    "    'Cinemateca Pernambucana',\n",
    "]\n",
    "\n",
    "def _uidcol(df):\n",
    "    return 'BB UID' if 'BB UID' in df.columns else 'UID'\n",
    "\n",
    "# UIDs j√° casados (para excluir)\n",
    "uids_casados = set(matches_all[_uidcol(matches_all)].unique())\n",
    "\n",
    "# Mapa UID -> plataformas whitelist + 1¬∫ deeplink\n",
    "uid_full = _uidcol(Base_BB_import)\n",
    "plat_map = (\n",
    "    Base_BB_import[[uid_full, 'Platform Name', 'Deeplink']]\n",
    "    .query(\"`Platform Name` in @PLATAFORMAS_FOCO\")\n",
    "    .sort_values(['Platform Name'])\n",
    "    .groupby(uid_full, as_index=False)\n",
    "    .agg({'Platform Name': lambda s: ' | '.join(sorted(set(s))),\n",
    "          'Deeplink': 'first'})\n",
    "    .rename(columns={'Platform Name':'Plataformas', 'Deeplink':'Deeplink_1'})\n",
    ")\n",
    "\n",
    "def _montar_lista(df_bb,\n",
    "                  precisa_br=None,            # True -> cont√©m 'BR'; False -> vazio/na; None -> ignora\n",
    "                  precisa_diretor=False,\n",
    "                  filtrar_plataforma=False,    # True em Estrg\n",
    "                  categoria=''):\n",
    "    uid = _uidcol(df_bb)\n",
    "\n",
    "    base = df_bb.copy()\n",
    "    base = base[~base[uid].isin(uids_casados)]\n",
    "\n",
    "    if precisa_br is True:\n",
    "        base = base[base['BB Countries'].astype(str).str.contains('BR', case=False, na=False)]\n",
    "    elif precisa_br is False:\n",
    "        base = base[~base['BB Countries'].astype(str).str.contains('BR', case=False, na=False)]\n",
    "        base = base[base['BB Countries'].isna() | (base['BB Countries'].astype(str).str.strip() == '')]\n",
    "\n",
    "    if precisa_diretor:\n",
    "        base = base[base['BB Directors'].astype(str).str.strip() != '']\n",
    "\n",
    "    if filtrar_plataforma:\n",
    "        base = base.merge(plat_map, left_on=uid, right_on=uid_full, how='inner')\n",
    "    else:\n",
    "        # s√≥ para exibi√ß√£o (n√£o filtra por plataforma)\n",
    "        base = base.merge(plat_map, left_on=uid, right_on=uid_full, how='left')\n",
    "\n",
    "    final_cols = [\n",
    "        uid, 'Platform Title', 'BB Original Title', 'BB Title', 'BB Year',\n",
    "        'Seasons', 'Episodes', 'Season Numbers',\n",
    "        'BB Directors', 'BB Primary Company', 'BB Production Companies',\n",
    "        'BB Countries', 'Plataformas', 'Deeplink_1'\n",
    "    ]\n",
    "    final_cols = [c for c in final_cols if c in base.columns]\n",
    "\n",
    "    out = base[final_cols].sort_values(['Plataformas','BB Year','BB Title'], na_position='last')\n",
    "    out['categoria'] = categoria\n",
    "\n",
    "    # Campos para trabalho manual (v√™m vazios)\n",
    "    for c in ['Respons√°vel', 'N¬∫ CPB encontrado', 'T√≠tulo encontrado', 'Observa√ß√£o']:\n",
    "        out[c] = pd.NA\n",
    "    return out\n",
    "\n",
    "# -------- 4 listas finais --------\n",
    "filmes_ESTR = _montar_lista(filmesEstr_BB_limpo, precisa_br=False, precisa_diretor=True,\n",
    "                            filtrar_plataforma=True,  categoria='filmes_ESTR')\n",
    "series_ESTR = _montar_lista(seriesEstr_BB_limpo, precisa_br=False, precisa_diretor=True,\n",
    "                            filtrar_plataforma=True,  categoria='series_ESTR')\n",
    "filmes_BR   = _montar_lista(filmesBR_BB_limpo,   precisa_br=True,  precisa_diretor=False,\n",
    "                            filtrar_plataforma=False, categoria='filmes_BR')\n",
    "series_BR   = _montar_lista(seriesBR_BB_limpo,   precisa_br=True,  precisa_diretor=False,\n",
    "                            filtrar_plataforma=False, categoria='series_BR')\n",
    "\n",
    "# Sanidade: interse√ß√£o deve ser 0\n",
    "u_estr = set(filmes_ESTR[_uidcol(filmes_ESTR)]) | set(series_ESTR[_uidcol(series_ESTR)])\n",
    "u_br   = set(filmes_BR[_uidcol(filmes_BR)])     | set(series_BR[_uidcol(series_BR)])\n",
    "print(\"Interse√ß√£o (UIDs em ESTR e BR):\", len(u_estr & u_br))\n",
    "\n",
    "# Exporta\n",
    "arq = \"Revisao - NaoMatch (Estrg por plataforma + BR) ‚Äî FINAL.xlsx\"\n",
    "with pd.ExcelWriter(arq, engine='openpyxl') as wr:\n",
    "    filmes_BR.to_excel(wr,   sheet_name='filmes_BR',   index=False)\n",
    "    series_BR.to_excel(wr,   sheet_name='series_BR',   index=False)\n",
    "    filmes_ESTR.to_excel(wr, sheet_name='filmes_ESTR', index=False)\n",
    "    series_ESTR.to_excel(wr, sheet_name='series_ESTR', index=False)\n",
    "print(\"Arquivo salvo:\", arq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe395ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estrg Filmes com diretor vazio:', (estrg_filmes['BB Directors'].isna() | (estrg_filmes['BB Directors'].astype(str).str.strip() == '')).sum())\n",
    "print('Estrg S√©ries com diretor vazio:', (estrg_series['BB Directors'].isna() | (estrg_series['BB Directors'].astype(str).str.strip() == '')).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f266343-bb08-452b-b56d-b0a74a34e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega a base \"estrangeira\" ANTES do merge\n",
    "base_fe = filmesEstr_BB_limpo.copy()   # idem para s√©ries depois\n",
    "uidc = 'BB UID' if 'BB UID' in base_fe.columns else 'UID'\n",
    "\n",
    "# quantos candidatos totais ap√≥s excluir casados?\n",
    "tmp = base_fe[~base_fe[uidc].isin(uids_casados)]\n",
    "\n",
    "# valida√ß√£o de diretor com uma limpeza mais r√≠gida (remove espa√ßos invis√≠veis tamb√©m)\n",
    "def _trim_hard(s):\n",
    "    s = s.astype(str).str.replace(r'[\\u00A0\\u2007\\u202F\\u200B-\\u200D]', '', regex=True)  # NBSP, thin spaces, zero-width\n",
    "    s = s.str.strip()\n",
    "    return s\n",
    "\n",
    "dir_raw  = tmp['BB Directors']\n",
    "dir_trim = _trim_hard(dir_raw)\n",
    "\n",
    "print('1A) candidatos p√≥s-exclus√£o de casados:', len(tmp))\n",
    "print('1B) com diretor VAZIO (ap√≥s trim hard):',\n",
    "      ((dir_trim.isna()) | (dir_trim == '') | (dir_trim.str.lower().isin(['nan','none']))).sum())\n",
    "\n",
    "# amostra de 10 problem√°ticos (se houver)\n",
    "bad_idx = ((dir_trim.isna()) | (dir_trim == '') | (dir_trim.str.lower().isin(['nan','none'])))\n",
    "display(tmp.loc[bad_idx, [uidc,'BB Title','BB Directors']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f6330-21a5-40fb-a34f-ab771d5cfea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstr√≥i a lista como no pipeline, mas guardando intermedi√°rios\n",
    "base_ok = tmp[_trim_hard(tmp['BB Directors']).ne('') & tmp['BB Directors'].notna()]\n",
    "out = base_ok.merge(uid_to_plats, left_on=uidc, right_on=_uid_col(Base_BB_import), how='left')\n",
    "out = out[out['Plataformas'].astype(str).str.strip().ne('') & out['Plataformas'].notna()].copy()\n",
    "\n",
    "# checagem p√≥s-merge\n",
    "dir_after = _trim_hard(out['BB Directors'])\n",
    "print('2) ap√≥s merge/filtro plataforma, diretor vazio =',\n",
    "      ((dir_after.isna()) | (dir_after == '') | (dir_after.str.lower().isin(['nan','none']))).sum())\n",
    "\n",
    "# se >0, mostra 10 linhas para inspecionar\n",
    "bad2 = ((dir_after.isna()) | (dir_after == '') | (dir_after.str.lower().isin(['nan','none'])))\n",
    "display(out.loc[bad2, [uidc,'BB Title','BB Directors','Plataformas']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ce11f-0edc-47d9-9453-91a8ce566d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usa exatamente o DF que voc√™ est√° salvando no Excel (ex.: estrg_filmes)\n",
    "print('estrg_filmes (linhas):', len(estrg_filmes))\n",
    "\n",
    "# valida√ß√£o direta no DF final\n",
    "df_final = estrg_filmes.copy()\n",
    "dtrim = df_final['BB Directors'].astype(str).replace(r'[\\u00A0\\u2007\\u202F\\u200B-\\u200D]', '', regex=True).str.strip()\n",
    "print('3) no DF final, diretor vazio =', ((dtrim=='') | dtrim.isna() | dtrim.str.lower().isin(['nan','none'])).sum())\n",
    "\n",
    "# Exporta CSV tempor√°rio s√≥ com as linhas \"suspeitas\", se houver\n",
    "sus = df_final[((dtrim=='') | dtrim.isna() | dtrim.str.lower().isin(['nan','none']))]\n",
    "sus.to_csv('suspeitos_diretor_vazio.csv', index=False, encoding='utf-8')\n",
    "print('CSV com suspeitos salvo (se n√£o estiver vazio): suspeitos_diretor_vazio.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790d2db-24f2-418c-b616-f8548fa08ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('linhas a exportar:', len(estrg_filmes))\n",
    "print('diretor vazio na exporta√ß√£o:',\n",
    "      (estrg_filmes['BB Directors'].isna() |\n",
    "       (estrg_filmes['BB Directors'].astype(str).str.strip() == '')).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bca087-545d-4bc5-af7d-72b47d0a9231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
